{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction 工作中碰到的一些知识。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-05-05 20:07:19 "},"2week/4_19/":{"url":"2week/4_19/","title":"测试与nio的Path,File","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 junit的Assert 2 Java 开发的模拟测试框架: Mockito 2.1 验证行为 2.2 Stub（存根/打桩） 2.3 参数匹配器 2.4 调用次数 2.5 简化Mock创建方式(注解) 2.6 间接依赖bean 2.7 @spy神器 2.8 api 3 nio的Path,File 3.1 路径 3.2 api 3.2.1 Paths 3.2.2 Path 3.2.3 Files 3.3 NIO和IO遍历指定目录效果对比 第2周-4.19 1 junit的Assert 2022-4-19 11:50:4 assert: 断言 junit断言总结 平时编写自己的测试类，如果没有断言，那么就没写测试的必要了。 JUnit框架用一组assert方法封装了最常见的测试任务。 junit中的assert方法全部放在Assert类中，都是静态方法。（因此可以静态引用） 方法 解释 assertTrue/False([String message,]boolean condition); 判断一个条件是true还是false fail([String message,]); 失败，可以有消息，也可以没有消息。 assertEquals([String message,]Object expected,Object actual); 判断是否相等，可以指定输出错误信息。第一个参数是期望值，第二个参数是实际的值。 assertNotNull/Null([String message,]Object obj); 判读一个对象是否非空(非空)。 assertSame/NotSame([String message,]Object expected,Object actual); 判断两个对象是否指向同一个对象。看内存地址。 failNotSame/failNotEquals(String message, Object expected, Object actual) 当不指向同一个内存地址或者不相等的时候，输出错误信息。 说白了，就是先提前断言（判断）想要得到的结果，如果与预想的不一致，Assert类就会抛出一个AssertionFailedError异常，Junit测试框架将这种错误归入Fails并且加以记录。 2 Java 开发的模拟测试框架: Mockito 2022-4-19 11:50:11 https://baijiahao.baidu.com/s?id=1727997644914260506&wfr=spider&for=pc https://blog.csdn.net/xiao__jia__jia/article/details/115252780 解决： 如何测试一个rest接口； 如何测试一个包含客户端调用服务端的复杂方法； 如何测试一个包含从数据库读取数据的复杂方法; ... 假设现在要测试method A, method A里面又依赖Method B、Method C、Method D，而依赖的这3个method又不好去构建（如ObsClient需要真实AK SK，HttpClient需要构建客户端与服务器，Database相对好构建，但是假设Method C只是从table1、table2联合查询，你还得分别往table1、table2 insert数据，很繁琐），这时候可以考虑Mockito进行优雅测试，当然如果你想去构建真实的测试场景，未免有点舍本逐末了 说白了，就是构造一些虚拟数据，来测试方法，避免大动干戈。 使用（可以静态引用）： 2.1 验证行为 一旦mock对象被创建了，mock对象会记住所有的交互。然后你就可以选择性的验证你感兴趣的交互，也就是说，你对这个Mock对象做的操作，都被记录下来了，验证的时候会是合法的。 @Test void testBehavior() { //构建moock数据 List list = mock(List.class); list.add(\"1\"); list.add(\"2\"); System.out.println(list.get(0)); // 会得到null ，前面只是在记录行为而已，没有往list中添加数据 verify(list).add(\"1\"); // 正确，因为该行为被记住了 verify(list).add(\"3\");//报错，因为前面没有记录这个行为 } 2.2 Stub（存根/打桩） 存根：用于预先说明当执行了什么操作的时候，产生一个什么响应， 存根特点：默认情况下，所有的函数都有返回值。 mock函数默认返回的是： null， 一个空的集合或者 一个被对象类型包装的内置类型，例如0、false对应的对象类型为Integer、Boolean； 测试桩函数可以被覆写 : 例如常见的测试桩函数可以用于初始化夹具，但是测试函数能够覆写它。请注意，覆写测试桩函数是一种可能存在潜在问题的做法；一旦测试桩函数被调用，该函数将会一致返回固定的值； 示例：常规存根，主要用到when 、thenReturn、then、thenThrow、thenAnswer这几个函数。 @Test void testStub() { List l = mock(ArrayList.class); when(l.get(0)).thenReturn(10); when(l.get(1)).thenReturn(20); when(l.get(2)).thenThrow(new RuntimeException(\"no such element\")); assertEquals(l.get(0), 10); assertEquals(l.get(1), 20); assertNull(l.get(4)); assertThrows(RuntimeException.class, () -> { int x = l.get(2); }); } void函数存根 主要用到doThrow(), doAnswer(), doNothing(), doReturn() and doCallRealMethod()等函数，当然，这些函数也可以用于有返回值的函数的存根； 需要注意的是，doCallRealMethod不能用于Mock对象，只能用于监察对象。 @Test void testVoidStub(){ List l = mock(ArrayList.class); doReturn(10).when(l).get(1); doThrow(new RuntimeException(\"you cant clear this List\")).when(l).clear(); assertEquals(l.get(1),10); assertThrows(RuntimeException.class,()->l.clear()); } 2.3 参数匹配器 在上面的stub测试中，我们需要对我们关系的数据一个一个的进行stub，如果数据过多的时候，会比较麻烦， 这个时候，我们可以利用参数匹配器来完成相应的操作，参数既可以用与stub，也可以用于验证的时候。 所有的参数匹配器都存放在org.mockito.ArgumentMatchers中。 @Test void testMatchers() { List l = mock(ArrayList.class); when(l.get(anyInt())).thenReturn(100); assertEquals(l.get(999),100); } 2.4 调用次数 校验某个操作执行的次数 @Test void testTimes() { List l = mock(ArrayList.class); when(l.get(anyInt())).thenReturn(100); System.out.println(l.get(0)); System.out.println(l.get(1)); System.out.println(l.get(1)); System.out.println(l.get(2)); System.out.println(l.get(2)); System.out.println(l.get(2)); System.out.println(l.get(2)); verify(l, times(7)).get(anyInt()); verify(l, atLeastOnce()).get(0); verify(l, atLeast(3)).get(2); verify(l, atMost(6)).get(2); verify(l, atMostOnce()).get(0); } 2.5 简化Mock创建方式(注解) @RunWith(MockitoJUnitRunner.class) vs MockitoAnnotations.initMocks(this) 可以通过@Mock注解来简化Mock对象的创建过程，这样的话，我们就可以在多个测试中直接共用这些mock对象了， 需要注意的是，我们需要在方法开始执行下面的操作：MockitoAnnotations.initMocks 但如果是专门的测试类的话，可以直接在类上添加@RunWith(MockitoJUnitRunner.class) @Mock private MyService myService; //会将MyService进行Mock @InjectMocks private MyController MyController; // 会向MyController注入Mock对象, 例如：myService @Before public void init() { MockitoAnnotations.initMocks(this); } 2.6 间接依赖bean 如果一个Bean A依赖于Bean B，而Bean B又依赖于Bean C，现在想对A的接口进行测试，又想把C Mock掉。 例如：MyFirstService 间接依赖了MyService, 下面演示如何将MyService进行隔离。 使用mock生成一个虚拟的对象，这样不需要在spring-test.xml文件单独配置这个myservice的Bean。 @Profile(\"development\") @Configuration public class MyServiceTestConfiguration { @Bean(name = \"myService\") @Primary // spring在寻找时，优先使用该bean public MyService myService() { return Mockito.mock(MyService.class); } } 测试: @ContextConfiguration(\"classpath:spring-test.xml\") @RunWith(SpringJUnit4ClassRunner.class) @ActiveProfiles(\"development\") public class myServiceImplTest { @Autowired private myFirstService myFirstService; } 2.7 @spy神器 spy类的原理是，如果不打桩默认都会执行真实的方法，如果打桩则返回桩实现。 对 spy 变量打桩时，如果使用 when 去设置模拟值时，他里面的代码逻辑依然会被执行，只是mock了返回结果； 使用 doReturn 设置模拟值的话，则不会出现这个问题！ A aSpy = spy(new A()); //aSpy.set...(); when(aSpy.service()).thenReturn(\"spy!\");//service()逻辑依然执行 doReturn(\"spy!\").when(aSpy).service();//service()不会执行 注意：spy后的实例，原有处理逻辑还在，但内部对象还得靠自己手动set进去 两个方法同个方法名，参数类型分别为Object 和 Collection， anyObject（）无法区分Object 和Collection，会导致程序走真实逻辑。 可以这样处理： anyCollection() 匹配Collection 和 any(MyClass.class) 2.8 api （一）Mockito org.mockito.Mockito是mockito提供的核心api，提供了大量的静态方法，用于帮助我们来mock对象，验证行为等等，然后需要注意的是，很多方法都被封装在了MockitoCore类里面，下面对一些常用的方法做一些介绍。 方法 解释 mock 构建一个我们需要的对象；可以mock具体的对象，也可以mock接口。 spy 构建监控对象 verify 验证某种行为 when 当执行什么操作的时候，一般配合thenXXX 一起使用。表示执行了一个操作之后产生什么效果。 doReturn 返回什么结果 doThrow 抛出一个指定异常 doAnswer 做一个什么相应，需要我们自定义Answer； times 某个操作执行了多少次 atLeastOnce 某个操作至少执行一次 atLeast 某个操作至少执行指定次数 atMost 某个操作至多执行指定次数 atMostOnce 某个操作至多执行一次 doNothing 不做任何处理 doReturn 返回一个结果 doThrow 抛出一个指定异常 doAnswer 指定一个操作，传入Answer doCallRealMethod 返回真实业务执行的结果，只能用于监控对象 （二）ArgumentMatchers 用于进行参数匹配，减少很多不必要的代码 方法 解释 anyInt 任何int类型的参数，类似的还有anyLong/anyByte等等。 eq 等于某个值的时候，如果是对象类型的，则看toString方法 isA 匹配某种类型 matches 使用正则表达式进行匹配 （三）OngoingStubbing OngoingStubbing用于返回操作的结果。 方法 解释 thenReturn 指定一个返回的值 thenThrow 抛出一个指定异常 then 指定一个操作，需要传入自定义Answer； thenCallRealMethod 返回真实业务执行的结果，只能用于监控对象。 3 nio的Path,File 2022-4-19 15:1:24 java7提供 在很多方面，java.nio.file.Path接口和java.io.File有相似性，但也有一些细微的差别。在很多情况下，可以用Path来代替File类。 3.1 路径 windows下绝对路径 Path path = Paths.get(\"c:\\\\data\\\\myfile.txt\"); //1 Path path = Paths.get(\"/home/jakobjenkov/myfile.txt\");//2. 会被解析成相对路径：base为C盘，从而对应绝对路径是：C:/home/jakobjenkov/myfile.txt linux下绝对路径 Path path = Paths.get(\"/home/jakobjenkov/myfile.txt\"); 3.2 api 3.2.1 Paths 方法 解释 Path get(String,...) 获得Path对象 3.2.2 Path 方法 解释 String toString() 返回调用 Path 对象的字符串表示形式 boolean starts With(String path) 判断是否以 path 路径开始 boolean ends With(String path) 判断是否以 path 路径结朿 boolean isAbsolute() 判断是否是绝对路径 Path getParento 返回Path对象包含整个路径，不包含 Path 对象指定的文件路径 Path getRoot() 返回调用 Path 对象的根路径 Path getFileName 返回与调用 Path 对象关联的文件名 int getNameCount() 返回Path 根目录后面元素的数量 Path getName (int idx) 返回指定索引位置idx 的路径名称 Path toAbsolute Path() 作为绝对路径返回调用 Path 对象 Path resolve(Path p) 合并两个路径，返回合并后的路径对应的Path对象 File toFile() 将Path转化为File类的对象 3.2.3 Files 1 用于操作文件或目录 方法 解释 Path copy(Path sc, Path dest, CopyOption ...how) 文件的复制 Path createDirectory(Path path, FileAttribute ...attr) 创建一个自录 Path createFile(Path path, FileAttribute ...arr) 创建一个文件 void delete (Path path) 删除一个文件/目录，如果不存在，执行报错 void deletelfExists (Path path) Path对应的文件/目录如果存在，执行删除 Path move(Path src. Path dest. CopyOption...how) 将src移动到dest 位置 long size(Path path) 返回 path 指定文件的大小 2 用于判断 方法 解释 boolean exists(Path path, LinkOption opts) 判断文件是否存在 boolean isDirectory(Path path, LinkOption opts) 判断是否是目录 boolean isRegularFile(Path path. LinkOption...opts) 判断是否是文件 boolean isHidden(Path path) 判断是否是隐薇文件 boolean isReadable(Path path) 判断文件是否可读 boolean isWritable(Path path) 判断文件是否可写 boolean notExists(Path path. LinkOptionu opts) 判断文件是否不存在 3 用于操作内容 方法 解释 SeekableByteChannel newByte Channel(Path path OpenOption...how) 获取与指定文件的连接，how 指定打开方式。 DirectoryStream newDirectoryStream(Path path) 打开path指定的目录 InputStream newlnputStream(Path path. OpenOption ... how) 获取InputStream对象 OutputStream newOutputStream(Path path, OpenOption ... how) 获取OutputStream对象 4 其它 Files.lines() 以Stream流的形式读取文件的所有行 /** * 以流的形式读取文件的所有行 * 读取的的字节是以UTF-8解码的字符集 * * @param path 文件的路径 * @return Stream 文件中的行组成的流 * @throws IOException 出现IO错误时抛出该异常 * @throws SecurityException 如果是默认提供程序,则安全管理器是已安装,检查读取方法来检查对文件的读取访问 */ public static Stream lines(Path path) throws IOException {} /** * 以流的形式读取文件的所有行 * 该方法和readAllLines不同,不会将所有行读取到一个List中,而是以流的形式进行惰性加载 * 以指定的解码的字符集读取字节,支持readAllLines的行终止符 * 当该方法返回时,后续读取文件发生的IOException将会在读取Stream流的方法处抛出一个包装的UncheckedIOException. * 如果关闭文件发生IOException也会包装成为一个UncheckedIOException * 返回的流封装了一个读取器,如果需要周期性的读取文件，需要使用try-with-resources语句来保证stream的close方法被调用,从而关闭打开的文件 * * @param path 文件的路径 * @param cs 指定的解码格式 * @return Stream 文件中的行组成的流 * @throws IOException 出现IO错误时抛出该异常 * @throws SecurityException 如果是默认提供程序,则安全管理器是已安装,检查读取方法来检查对文件的读取访问 */ public static Stream lines(Path path, Charset cs) throws IOException {} 3.3 NIO和IO遍历指定目录效果对比 利用IO的File递归遍历目录： public static void showPath(String dir){ File files = new File(dir); if (files.isDirectory()) { for (File file: files.listFiles() ) { System.out.println(file.getAbsolutePath()); showPath(file.getAbsolutePath().toString()); } }else{ return; } } 采用NIO的Files.walk方法，借助Stream流 直接逐一把目录打印出来： public static void printDir(String dir){ Path path = Paths.get(dir); try { Files.walk(path).forEach(System.out::println); } catch (IOException e) { e.printStackTrace(); } } 汽车为你造好了，没必要再骑车上高速了。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-05-19 18:51:06 "},"2week/4_20/":{"url":"2week/4_20/","title":"maven","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 maven 1.1 生命周期 1.2 maven寻找依赖流程 1.3 idea里的maven wrapper 第2周-4.20 1 maven 2022-4-20 9:57:7 1.1 生命周期 1 compile mvn compile会在当前目录生成target目录。 2 clean mvn clean删除当前目录中的target目录。 3 package mvn package将本地工程打包成jar包。 4 install mvn install将本地工程打包成jar包，放入到本地仓库中。 之后，其它Maven管理的项目可以通过pom.xml配置依赖引入到其工程。 其它 mvn -DskipTests，不执行测试用例，但编译测试用例类生成相应的class文件至target/test-classes下。 mvn -Dmaven.test.skip=true，不执行测试用例，也不编译测试用例类。 1.2 maven寻找依赖流程 Maven 将从本地资源库获得 Maven 的本地资源库依赖资源(默认用户目录下的.m2目录)，如果没有找到， 它会从默认的 Maven 中央存储库 – http://repo1.maven.org/maven2/ 查找下载，如果还是没有找到， 它会从配置的远程存储库（包括私服、JBOSS仓库和java.net仓库）查找下载。 1.3 idea里的maven wrapper 要使用maven wrapper有2种方式： 1、 主动生成： mvn -N io.takari:maven:0.7.6:wrapper 会生成3个文件： mvnw(linux命令) mvnw.cmd(windows命令) .mvn目录 2、从别的项目中将这3个文件copy过来 有了这3个文件后， maven的具体版本只依赖于当前项目中(.mvn/wrapper/maven-wrapper.properties)所配置的maven版本。 在项目目录下，使用mvnw代替以前的mvn命令。 mvnw会在每次执行命令时检测${home}/.m2/wrapper/dists目录下是否有maven-wrapper.properties中指定Maven版本，如果没有就将maven环境自动下载到dists目录。 maven的配置文件settings.xml必须在{user}/.m2目录下 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-04-20 13:40:43 "},"2week/4_22/":{"url":"2week/4_22/","title":"idea的git标签中的符号含义","keywords":"","body":"第2周-4.22 1 idea的git标签中的符号含义 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-04-22 15:03:58 "},"3week/4_27/":{"url":"3week/4_27/","title":"linux -- less","keywords":"","body":"第3周-4.27 1 linux -- less less is more. less [-options] []表示可选，<>表示必选 options desc -b 《缓冲区大小》 设置缓冲区的大小 -e 当文件显示结束后，自动离开 -f 强迫打开特殊文件，例如外围设备代号、目录和二进制文件 -g 只标志最后搜索的关键词 -i 忽略搜索时的大小写 -m 显示类似more命令的百分比 -N 显示每行的行号 -o 《文件名》 将less 输出的内容在指定文件中保存起来 -Q 不使用警告音 -s 显示连续空行为一行 -S 行过长时间将超出部分舍弃 -x 《数字》 将“tab”键显示为规定的数字空格 常用命令：less -mN 在查看期间，可通过以下命令来操作阅读文件： 当往下看浏览的时候，后代表下，前代表上； 当往上看浏览的时候，后代表上，前代表下。 operation desc /str 向后搜索“str”的功能 ?str 向前搜索“str”的功能 n 重复前一个搜索(与 / 或 ? 有关) N 反向重复前一个搜索(与 / 或 ? 有关) b 向前翻一页 d 向后翻半页 h 显示帮助界面 Q 退出less 命令 u 向前滚动半页 y 向前滚动一行 空格键 滚动一行 回车键 滚动一页 [pagedown] 向下翻动一页 [pageup] 向上翻动一页 g 跳到文件头 【常用】 G 跳到文件尾部 【常用】 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-04-28 10:35:03 "},"4week/5_3/":{"url":"4week/5_3/","title":"java里执行第三方脚本","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 java里执行第三方脚本 1.1 Process.exitValue() 1.2 Process.waitFor() 2 idea等ide的build区别 3 ExecutorService API 第4周-5.3 1 java里执行第三方脚本 When Runtime.exec() won't 简析 Runtime.exec(..) java 程序中，如果我们想执行一些 Shell 命令或其他外部应用程序，通常都是使用java.lang.Runtime.exec(..)方法来执行的。 当 Java 内置的 Runtime.exec(..) 方法在执行外部命令时，可能存在一些不易察觉的坑，往往会导致程序运行失败。 1.1 Process.exitValue() IllegalThreadStateException异常：Runtime.exe(..)可能出现IllegalThreadStateException异常。我们通常使用exec(..)方法执行 JVM 外部程序，如果想查看外部程序返回值，可以使用Process.exitValue()方法。 需要注意的是，如果直接使用Process.exitValue()获取外部程序返回值，如果此时外部程序还未运行完成，则会抛出IllegalThreadStateException异常。 举个栗子：比如在 Java 中执行 javac 程序，并获取其返回值。 代码如下： public class BadExecJavac { public static void main(String[] args) throws IOException { Process pid = Runtime.getRuntime().exec(\"javac\"); int exitValue = pid.exitValue(); System.out.println(\"Process exitValue: \" + exitVal); } } 使用Process.waitFor()替换Process.exitValue()。 1.2 Process.waitFor() Process.waitFor()与Process.exitValue()同样会返回外部程序的执行结果，但是它会阻塞直到外部程序运行结束。 代码如下： public static void main(String[] args) throws IOException, InterruptedException { Process pid = Runtime.getRuntime().exec(\"javac\"); int exitValue = pid.waitFor(); System.out.println(\"Process exitValue: \" + exitValue); } 注：Process.exitValue()/Process.waitFor()获取外部程序的返回值为 0 表示执行成功，其余值表示外部程序执行出错。 综上：要解决IllegalThreadStateException异常， 要么就是手动捕获Process.exitValue()抛出的异常， 要么就使用Process.waitFor()（推荐）等待外部程序正常运行结束。 2 idea等ide的build区别 compile：只编译选定的目标。 make：只编译选定的目标，只编译上次编译后，产生过变化的文件。 build：对整个工程进行编译。 但现在都用第三方工具进行源码编译的管理，如：ant,maven等工具。 即maven的package、install等已经替代了ide提供的build。 3 ExecutorService API 控制线程池启停的接口。 ExecutorService Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-05-03 17:04:35 "},"4week/5_4/":{"url":"4week/5_4/","title":"spring batch","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 spring batch 1.1 Job 1.1.1 JobInstance 1.1.2 JobParameters 1.1.3 JobExecution 1.2 Step 1.2.1 StepExecution 1.2.2 ExecutionContext 1.3 JobRepository 1.4 JobLauncher 1.5 Item Reader 1.6 Item Processor 1.7 Item Writer 1.8 chunk 处理流程 1.9 skip策略和失败处理 1.10 批处理操作指南 1.10.1 批处理原则 1.10.2 如何默认不启动job 1.11 @stepScope 第4周-5.4 1 spring batch 批处理框架 spring batch 这么强，你会用吗？ 一个典型的批处理应用程序大致如下： 读：从数据库，文件或队列中读取大量记录。 处理：以某种方式处理数据。 写：以修改之后的形式写回数据。 其对应的示意图如下： spring batch的一个总体的架构如下： 在spring batch中一个job可以定义很多的步骤step， 在每一个step里面可以定义其专属的 ItemReader用于读取数据， ItemProcesseor用于处理数据， ItemWriter用于写数据， 而每一个定义的job则都在JobRepository里面， 我们可以通过JobLauncher来启动某一个job。 1.1 Job Job和Step是spring batch执行批处理任务最为核心的两个概念。 Job是一个封装整个批处理过程的一个概念。Job在spring batch的体系当中只是一个最顶层的一个抽象概念，体现在代码当中则它只是一个最上层的接口，其代码如下: /** * Batch domain object representing a job. Job is an explicit abstraction * representing the configuration of a job specified by a developer. It should * be noted that restart policy is applied to the job as a whole and not to a * step. */ public interface Job{ String getName( ) ; boolean isRestartable( ) ; void execute( JobExecution execution) ; JobParametersIncrementer getJobParametersIncrementer( ) ; JobParametersValidator getJobParametersValidator( ) ; } 在Job这个接口当中定义了五个方法，它的实现类主要有两种类型的job， 一个是simplejob， 另一个是flowjob。 在spring batch当中，job是最顶层的抽象，除job之外我们还有JobInstance以及JobExecution这两个更加底层的抽象。 一个job是我们运行的基本单位，它内部由step组成。job本质上可以看成step的一个容器。 一个job可以按照指定的逻辑顺序组合step，并提供了我们给所有step设置相同属性的方法，例如一些事件监听，跳过策略。 Spring Batch以SimpleJob类的形式提供了Job接口的默认简单实现，它在Job之上创建了一些标准功能。 一个使用java config的例子代码如下： @Bean public Job footballJob { return this.jobBuilderFactory.get(\"footballJob\") .start(playerLoad) .next(gameLoad) .next(playerSummarization) .end .build; } 这个配置的意思是：首先给这个job起了一个名字叫footballJob，接着指定了这个job的三个step，他们分别由方法: playerLoad, gameLoad, playerSummarization 实现。 1.1.1 JobInstance 在上文已经提到了JobInstance，他是Job的更加底层的一个抽象，他的定义如下： public interface JobInstance { /** * Get unique id for this JobInstance. * @return instance id */ public long getInstanceId; /** * Get job name. * @return value of 'id' attribute from */ public String getJobName; } 方法很简单，一个是返回Job的id，另一个是返回Job的名字。 JobInstance指的是job运行当中，作业执行过程当中的概念。Instance本就是实例的意思。 比如说现在有一个批处理的job，它的功能是在一天结束时执行行一次。我们假定这个批处理job的名字为'EndOfDay'。在这个情况下，那么每天就会有一个逻辑意义上的JobInstance, 而我们必须记录job的每次运行的情况。 1.1.2 JobParameters 在上文当中我们提到了，同一个job每天运行一次的话，那么每天都有一个jobIntsance，但他们的job定义都是一样的，那么我们怎么来区别一个job的不同jobinstance了。 不妨先做个猜想，虽然jobinstance的job定义一样，但是他们有的东西就不一样，例如运行时间。 因此，我们可以通过把运行时间当作Jobparameter来操作正确的JobInstance。 1.1.3 JobExecution JobExecution指的是单次尝试运行一个我们定义好的Job的代码层面的概念。 job的一次执行可能以失败也可能成功。只有当执行成功完成时，给定的JobExecution与执行相对应的JobInstance才也被视为完成。 还是以前面描述的EndOfDay的job作为示例，假设第一次运行01-01-2019的JobInstance结果是失败。那么此时如果使用与第一次运行相同的Jobparameter参数（即01-01-2019）作业参数再次运行，那么就会创建一个对应于之前jobInstance的一个新的JobExecution实例,JobInstance仍然只有一个。 JobExecution的接口定义如下： public interface JobExecution{ /** * Get unique id for this JobExecution. * @return execution id */ public longget ExecutionId( ) ; /** * Get job name. * @return value of 'id' attribute from */ public String getJobName( ) ; /** * Get batch status of this execution. * @return batch status value. */ public BatchStatus getBatchStatus( ) ; /** * Get time execution entered STARTED status. * @return date (time) */ public Date getStartTime( ) ; /** * Get time execution entered end status: COMPLETED, STOPPED, FAILED * @return date (time) */ public Date getEndTime( ) ; /** * Get execution exit status. * @return exit status. */ public String getExitStatus( ) ; /** * Get time execution was created. * @return date (time) */ public Date getCreateTime( ) ; /** * Get time execution was last updated updated. * @return date (time) */ public Date getLastUpdatedTime( ) ; /** * Get job parameters for this execution. * @return job parameters */ public Properties getJobParameters( ) ; } 只提一下BatchStatus，JobExecution当中提供了一个方法getBatchStatus用于获取一个job某一次特地执行的一个状态。 BatchStatus是一个代表job状态的枚举类，其定义如下： public enum BatchStatus{ STARTING, STARTED, STOPPING, STOPPED, FAILED, COMPLETED, ABANDONED } 这些属性对于一个job的执行来说是非常关键的信息，并且spring batch会将他们持久到数据库当中. 在使用Spring batch的过程当中spring batch会自动创建一些表用于存储一些job相关的信息，用于存储JobExecution的表为batch_job_execution。 1.2 Step 每一个Step对象都封装了批处理作业的一个独立的阶段。事实上，每一个Job本质上都是由一个或多个步骤组成。每一个step包含定义和控制实际批处理所需的所有信息。任何特定的内容都由编写Job的开发人员自行决定。 一个step可以非常简单也可以非常复杂。例如，一个step的功能是将文件中的数据加载到数据库中，那么基于现在spring batch的支持则几乎不需要写代码。更复杂的step可能具有复杂的业务逻辑，这些逻辑作为处理的一部分。 与Job一样，Step具有与JobExecution类似的StepExecution，如下图所示： 1.2.1 StepExecution StepExecution表示一次执行Step, 每次运行一个Step时都会创建一个新的StepExecution，类似于JobExecution。但是，某个步骤可能由于其之前的步骤失败而无法执行。且仅当Step实际启动时才会创建StepExecution。 一次step执行的实例由StepExecution类的对象表示。每个StepExecution都包含对其相应步骤的引用以及JobExecution和事务相关的数据，例如提交和回滚计数以及开始和结束时间。 此外，每个步骤执行都包含一个ExecutionContext，其中包含开发人员需要在批处理运行中保留的任何数据，例如重新启动所需的统计信息或状态信息。 1.2.2 ExecutionContext ExecutionContext即每一个StepExecution 的执行环境。它包含一系列的键值对。我们可以用如下代码获取ExecutionContext: ExecutionContextecStep = stepExecution.getExecutionContext; ExecutionContextecJob = jobExecution.getExecutionContext; 1.3 JobRepository JobRepository是一个用于将上述job，step等概念进行持久化的一个类。它同时给Job和Step以及下文会提到的JobLauncher实现提供CRUD操作。 首次启动Job时，将从repository中获取JobExecution，并且在执行批处理的过程中，StepExecution和JobExecution将被存储到repository当中。 @EnableBatchProcessing注解可以为JobRepository提供自动配置。 1.4 JobLauncher JobLauncher这个接口的功能非常简单，它是用于启动指定了JobParameters的Job，为什么这里要强调指定了JobParameter，原因其实我们在前面已经提到了，jobparameter和job一起才能组成一次job的执行。 public interface JobLauncher{ public JobExecution run(Job job, JobParameters jobParameters) throws JobExecutionAlreadyRunningException, JobRestartException, JobInstanceAlreadyCompleteException, JobParametersInvalidException; } 上面run方法实现的功能是根据传入的job以及jobparamaters从JobRepository获取一个JobExecution并执行Job。 1.5 Item Reader ItemReader是一个读数据的抽象，它的功能是为每一个Step提供数据输入。 当ItemReader以及读完所有数据时，它会返回null来告诉后续操作数据已经读完。 Spring Batch为ItemReader提供了非常多的有用的实现类，比如JdbcPagingItemReader，JdbcCursorItemReader等等。 ItemReader支持的读入的数据源也是非常丰富的，包括各种类型的数据库，文件，数据流，等等。几乎涵盖了我们的所有场景。 下面是一个JdbcPagingItemReader的例子代码： @Bean public JdbcPagingItemReader itemReader(DataSource dataSource, PagingQueryProvider queryProvider) { Map parameterValues = new HashMap<>(); parameterValues.put( \"status\", \"NEW\"); return new JdbcPagingItemReaderBuilder () .name( \"creditReader\") .dataSource(dataSource) .queryProvider(queryProvider) .parameterValues(parameterValues) .rowMapper(customerCreditMapper) .pageSize( 1000) .build; } @Bean public SqlPagingQueryProviderFactoryBean queryProvider { SqlPagingQueryProviderFactoryBean provider = new SqlPagingQueryProviderFactoryBean(); provider.setSelectClause( \"select id, name, credit\"); provider.setFromClause( \"from customer\"); provider.setWhereClause( \"where status=:status\"); provider.setSortKey( \"id\"); return provider; } JdbcPagingItemReader必须指定一个PagingQueryProvider，负责提供SQL查询语句来按分页返回数据。 下面是一个JdbcCursorItemReader的例子代码: private JdbcCursorItemReader> buildItemReader(final DataSource dataSource, StringtableName, Stringtenant) { JdbcCursorItemReader> itemReader = new JdbcCursorItemReader<>(); itemReader.setDataSource(dataSource); itemReader.setSql( \"sql here\"); itemReader.setRowMapper( newRowMapper); return itemReader; } 1.6 Item Processor ItemProcessor对项目的业务逻辑处理的一个抽象, 当ItemReader读取到一条记录之后，ItemWriter还未写入这条记录之前，我们可以借助ItemProcessor提供一个处理业务逻辑的功能，并对数据进行相应操作。 如果我们在ItemProcessor发现一条数据不应该被写入，可以通过返回null来表示。ItemProcessor和ItemReader以及ItemWriter可以非常好的结合在一起工作，他们之间的数据传输也非常方便。我们直接使用即可。 1.7 Item Writer 既然ItemReader是读数据的一个抽象，那么ItemWriter自然就是一个写数据的抽象，它是为每一个step提供数据写出的功能。写的单位是可以配置的，我们可以一次写一条数据，也可以一次写一个chunk的数据，关于chunk下文会有专门的介绍。ItemWriter对于读入的数据是不能做任何操作的。 Spring Batch为ItemWriter也提供了非常多的有用的实现类，当然我们也可以去实现自己的writer功能。 1.8 chunk 处理流程 spring batch提供了让我们按照chunk处理数据的能力，一个chunk的示意图如下： 所图所示，由于我们一次batch的任务可能会有很多的数据读写操作，因此一条一条的处理并向数据库提交的话效率不会很高，因此spring batch提供了chunk这个概念，我们可以设定一个chunk size，spring batch 将一条一条处理数据，但不提交到数据库，只有当处理的数据数量达到chunk size设定的值的时候，才一起去commit. java的实例定义代码如下： @Bean public Job sampleJob(){ return this.jobBuilderFactory.get(\"sampleJob\") .start(step1()) .end() .build(); } @Bean public Step step1() { return this. stepBuilderFactory.get (\"step1\") .chunk(10) .reader(itemReader()) .writer(itemWriter()) .build(); } 在上面这个step里面，chunk size被设为了10，当ItemReader读的数据数量达到10的时候，这一批次的数据就一起被传到itemWriter，同时transaction被提交。 1.9 skip策略和失败处理 一个batch的job的step，可能会处理非常大数量的数据，难免会遇到出错的情况，出错的情况虽出现的概率较小，但是我们不得不考虑这些情况，因为我们做数据迁移最重要的是要保证数据的最终一致性。 spring batch当然也考虑到了这种情况，并且为我们提供了相关的技术支持，请看如下bean的配置： @Bean public Step step1() { return this. stepBuilderFactory.get(\"step1\") .chunk(10) .reader(flatFileItemReader()) .writer(itemwriter()) .faultTolerant() .skipLimit(10) .skip(Exception.class) .noSkip(FileNotFoundException.class) .build(); 我们需要留意这三个方法，分别是: skipLimit: 意思是我们可以设定一个我们允许的这个step可以跳过的异常数量，假如我们设定为10，则当这个step运行时，只要出现的异常数目不超过10，整个step都不会fail。注意，若不设定skipLimit，则其默认值是0. skip: 我们可以指定我们可以跳过的异常，因为有些异常的出现，我们是可以忽略的。 noSkip: 指出现这个异常我们不想跳过，也就是从skip的所有exception当中排除这个exception，从上面的例子来说，也就是跳过所有除FileNotFoundException的exception。 那么对于这个step来说，FileNotFoundException就是一个fatal的exception，抛出这个exception的时候step就会直接fail。 1.10 批处理操作指南 一些使用spring batch时的值得注意的点 1.10.1 批处理原则 在构建批处理解决方案时，应考虑以下关键原则和注意事项。 批处理体系结构通常会影响体系结构 尽可能简化并避免在单批应用程序中构建复杂的逻辑结构 保持数据的处理和存储在物理上靠得很近（换句话说，将数据保存在处理过程中）。 最大限度地减少系统资源的使用，尤其是I / O. 在internal memory中执行尽可能多的操作。 查看应用程序I / O（分析SQL语句）以确保避免不必要的物理I / O. 特别是，需要寻找以下四个常见缺陷： 当数据可以被读取一次并缓存或保存在工作存储中时，读取每个事务的数据。 重新读取先前在同一事务中读取数据的事务的数据。 导致不必要的表或索引扫描。 未在SQL语句的WHERE子句中指定键值。 在批处理运行中不要做两次一样的事情。例如，如果需要数据汇总以用于报告目的，则应该（如果可能）在最初处理数据时递增存储的总计，因此您的报告应用程序不必重新处理相同的数据。 在批处理应用程序开始时分配足够的内存，以避免在此过程中进行耗时的重新分配。 总是假设数据完整性最差。插入适当的检查和记录验证以维护数据完整性。 尽可能实施校验和以进行内部验证。例如，对于一个文件里的数据应该有一个数据条数纪录，告诉文件中的记录总数以及关键字段的汇总。 在具有真实数据量的类似生产环境中尽早计划和执行压力测试。 在大批量系统中，数据备份可能具有挑战性，特别是如果系统以24-7在线的情况运行。数据库备份通常在在线设计中得到很好的处理，但文件备份应该被视为同样重要。如果系统依赖于文件，则文件备份过程不仅应该到位并记录在案，还应定期进行测试。 1.10.2 如何默认不启动job 在使用java config使用spring batch的job时，如果不做任何配置，项目在启动时就会默认去跑我们定义好的批处理job。那么如何让项目在启动时不自动去跑job呢？ spring batch的job会在项目启动时自动run，如果我们不想让他在启动时run的话，可以在application.properties中添加如下属性： spring.batch.job.enabled= false 在读数据时内存不够 在使用spring batch做数据迁移时，发现在job启动后，执行到一定时间点时就卡在一个地方不动了，且log也不再打印，等待一段时间之后，得到如下错误： 红字的信息为：Resource exhaustion event：the JVM was unable to allocate memory from the heap. 翻译过来的意思就是项目发出了一个资源耗尽的事件，告诉我们java虚拟机无法再为堆分配内存。 造成这个错误的原因是: 这个项目里的batch job的reader是一次性拿回了数据库里的所有数据，并没有进行分页，当这个数据量太大时，就会导致内存不够用。解决的办法有两个: 调整reader读数据逻辑，按分页读取，但实现上会麻烦一些，且运行效率会下降 增大service内存 1.11 @stepScope Spring Batch中@StepScope的适用范围及理解 先说一下IOC容器中几种bean的作用范围(scope): singleton: 全局有且仅有一个实例 prototype: 每次获取Bean的时候会有一个新的实例 request: request表示该针对每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTP request内有效 session: session作用域表示该针对每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTP session内有效 globalsession: global session作用域类似于标准的HTTP Session作用域，不过它仅仅在基于portlet的web应用中才有意义 使用Spring Batch批处理框架时,batch框架中特有的bean作用范围注解@StepScope， xml配置为 Spring batch框架只有在批处理时才需要实例化job以及对应的最底层处理单位(reader,processor,writer,tasklet) 而job启动后的运行参数一旦确定便无法修改。 为了使每一次启动job时使处理单位的参数可以动态修改(比如第一次job启动时参数tranDate=\"20210101\",第二次job参数启动时参数改为tranDate=\"20210102\"). 所以设计了@StepScope配合@Value(\"#{jobParameters['contractInfoDat']}\") 从job的启动参数中获取所需参数。 @StepScope只能用在最底层处理单位(reader,processor,writer,tasklet)的方法上,配合@Bean使用。 被@StepScope注解修饰的bean只会在step启动时进行初始化,step处理完成后便会被销毁,即同一个Step执行两次你会发现Writer创建了两次。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-05-04 19:00:31 "},"4week/5_5/":{"url":"4week/5_5/","title":"spring中单例bean引用原型bean","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 spring中单例bean引用原型bean 1.1 场景：单例bean引用不变的原型对象 1.1.1 xml文件内容 1.1.2 测试和结果 1.2 保证单例bean引用的原型始终是新建对象 1.2.1 更新xml文件 1.2.2 测试和结果 1.3 源码原理 1.3.1 初始化设置属性 1.3.2 执行getHeadMaster和getStudent后 2 StringBuffer清空操作 3 stream 3.1 介绍 3.2 生命周期 3.3 操作api 3.3.1 创建流 3.3.2 中间操作 3.3.3 终端操作 3.4 总结 4 Files.lines使用注意事项 4.1 使用try-with-resources 5 spring xml bean的property的简写——p命令空间 第4周-5.5 1 spring中单例bean引用原型bean spring中单例bean引用原型bean 1.1 场景：单例bean引用不变的原型对象 1.1.1 xml文件内容 定义headMaster和student对原型bean，teacher为单例bean。其中teacher中注入headMaster和student属性。 1.1.2 测试和结果 单例bean的teacher中，headMaster和student属性始终不变。从applicationContext中重新获取对应bean后，返回新建对象。 public static void main(String[] args) { ClassPathXmlApplicationContext ac = new ClassPathXmlApplicationContext(\"bean/scope/scope.xml\"); Teacher teacher = ac.getBean(\"teacher\", Teacher.class); HeadMaster headMaster = teacher.getHeadMaster(); Student student = teacher.getStudent(); HeadMaster headMasterTwo = teacher.getHeadMaster(); Student studentTwo = teacher.getStudent(); System.out.println(headMaster); System.out.println(headMasterTwo); System.out.println(ac.getBean(\"headMaster\", HeadMaster.class)); System.out.println(student); System.out.println(studentTwo); System.out.println(ac.getBean(\"student\", Student.class)); } /* * com.spring.learn.common.staff.HeadMaster@569cfc36 * com.spring.learn.common.staff.HeadMaster@569cfc36 * com.spring.learn.common.staff.HeadMaster@33723e30 * com.spring.learn.common.staff.Student@64f6106c * com.spring.learn.common.staff.Student@64f6106c * com.spring.learn.common.staff.Student@553a3d88 */ 1.2 保证单例bean引用的原型始终是新建对象 引入 lookup-method或者 replace-method。 1.2.1 更新xml文件 1.2.2 测试和结果 public static void main(String[] args) { ClassPathXmlApplicationContext ac = new ClassPathXmlApplicationContext(\"bean/scope/scope2.xml\"); Teacher teacher = ac.getBean(\"teacher\", Teacher.class); HeadMaster headMaster = teacher.getHeadMaster(); Student student = teacher.getStudent(); HeadMaster headMasterTwo = teacher.getHeadMaster(); Student studentTwo = teacher.getStudent(); System.out.println(headMaster); System.out.println(headMasterTwo); System.out.println(ac.getBean(\"headMaster\", HeadMaster.class)); System.out.println(student); System.out.println(studentTwo); System.out.println(ac.getBean(\"student\", Student.class)); } /* * com.spring.learn.common.staff.HeadMaster@6b67034 * com.spring.learn.common.staff.HeadMaster@16267862 * com.spring.learn.common.staff.HeadMaster@71248c21 * com.spring.learn.common.staff.Student@442675e1 * com.spring.learn.common.staff.Student@6166e06f * com.spring.learn.common.staff.Student@49e202ad */ 1.3 源码原理 本质上就是对getStudent和getHeadMaster加一层cglib代理，每次执行方法前会经过拦截器，返回application.getBean方法返回的bean对象。 1.3.1 初始化设置属性 初始化teacher时， AbstractAutowireCapableBeanFactory类中的: // lookup-method标签识别入口 522行：mbdToUse.prepareMethodOverrides(); AbstractBeanDefinition类中的: // BeanDefinition类中的参数methodOverrides，中的参数overrides>。 // MethodOverride中的属性参数overloaded 设置为false 1134行：getMethodOverrides().getOverrides().forEach(this::prepareMethodOverride); 1.3.2 执行getHeadMaster和getStudent后 CglibSubclassingInstantiationStrategy类中的intercept方法: // 从当前bean的BeanDefinition信息中，获取重写方法列表中的lookup方法对象。 // 根据此对象信息完成指定对象的实例化 238行：LookupOverride lo = (LookupOverride) getBeanDefinition().getMethodOverrides().getOverride(method); // 返回 根据xml文件中lookup-method指定bean值，从applicationContext中获取bean的对象。 242行：Object bean = (argsToUse != null ? this.owner.getBean(lo.getBeanName(), argsToUse) : this.owner.getBean(lo.getBeanName())); 2 StringBuffer清空操作 StringBuffer清空操作delete和setLength的效率对比分析 setLength()方法用时较短，因此在StringBuffer 清空操作中，使用setLength(int newLength)方法效率较高。 3 stream 「再学一次系列」一文弄懂Stream API，基操勿6 3.1 介绍 流的主要目的就是进行表达计算。 stream流是通过一组原始数据源转化生成的元素序列，支持: 数据处理操作（类似数据库的部分操作） 类其他函数式编程语言中的常用操作，如：filter、map等 3.2 生命周期 类似于一瓶矿泉水的生产： 获取水源（准备原始数据）：生成流的元素序列； 进入工作台（多个工作台）：流的中间操作，可以有多个中间操作进行衔接，中间操作返回的结果还是一个流； 装瓶（结束工作）：流的终端操作，无返回值，或返回一个非流结果。 3.3 操作api 3.3.1 创建流 创建流的方式常见包括： Collections.stream() Stream.of(args) 创建初始流，包含三个属性(值)： 姓名（卡诺1 - 卡诺5） 年龄（11 - 15） 性别（0 / 1） 后续操作均基于此数据: /** * 初始化用户元素序列 * @return */ public Stream userStream() { // 初始化集合数据 List users = new ArrayList<>(); for (int i = 0; i 3.3.2 中间操作 1 filter 过滤器 接受一个Predicate表达式，筛选满足条件的数据. public void testFilter(){ userStream().filter(user -> user.getAge() > 14)// 筛选出年龄大于14岁的user .forEach(System.out::println); // 遍历: User(name=卡诺5, age=15, gender=0) } 注意：forEach为终端操作 2 sort 排序 存在重载方法， sorted(), sorted(Comparator comparator) public void testSort(){ userStream() .sorted((u1, u2) -> u2.getAge() - u1.getAge()) // 增加一个比较器，按照年龄降序 .forEach(System.out::println); // 遍历，倒叙输出所有 } 3 limit 截断流 获取指定个数的元素，如果实际小于指定数，那么有多少返回多少。 userStream() .sorted((u1, u2) -> u2.getAge() - u1.getAge())// 增加一个比较器，按照年龄降序 .limit(1) // 获取排序后的第一个数据 .forEach(System.out::println); // 遍历: User(name=卡诺5, age=15, index=0) 4 skip 跳过 跳过指定个数元素，如果实际小于指定数，那么返回一个空流 userStream() .skip(4) // 跳过前四个 .forEach(System.out::println); // 遍历: User(name=卡诺5, age=15, index=0) 5 distinct 去重 如果操作的元素是对象，则依据对象的hashcode和equals进行去重。 Stream.of(1, 1, 3, 2, 3) .distinct() // 去重 .forEach(System.out::print); // 132 6 map 映射 将流中元素通过操作变成新的元素，接受一个Function表达式。 userStream() .map(User::getName) // 映射出所有名字 .forEach(System.out::print); // 卡诺1卡诺2卡诺3卡诺4卡诺5 7 flatMap 映射 将元素变成新的流，然后把多个新的流再变成一个流 // 将名字构建成Stream流 Function> flatMapFunction = user -> Stream .builder() .add(user.getName()) .build(); // map userStream() .map(flatMapFunction) // 接收一个Stream .forEach(System.out::println); // java.util.stream.ReferencePipeline$Head@7a1ebcd8 // flatMap userStream() .flatMap(flatMapFunction) // 接收一个Stream .forEach(System.out::print); // 卡诺1卡诺2卡诺3卡诺4卡诺5 通过上面的案例可以看出，map返回的是名字构建成Stream流，flatMap则是将返回的流的泛型值平铺合并成一个新的数据元素序列。 3.3.3 终端操作 1 forEach 遍历元素 userStream().forEach(System.out::println); 2 count 统计总数 类似SQL中的count，统计数据 long count = userStream().count(); System.out.println(count); // 5 3 max 获取最大值 max参数为比较器函数，返回类型是Optional Integer max = Stream.of(1, 2, 3, 4) .max(Comparator.comparingInt(t -> t)) .get(); System.out.println(max); // 4 注意： Comparator.comparingInt(t -> t) 与(t1, t2)-> t1 - t2等价，是Java为我们封装好的Lambda写法。 4 min 获取最小值 与max用法一致 Integer min = Stream.of(1, 2, 3, 4) .min(Comparator.comparingInt(t -> t)) .get(); System.out.println(min); // 1 5 findFirst 获取第一个 返回类型是Optional，如果值不存在，返回的是空的Optional Optional firstUser = userStream().findFirst(); System.out.println(firstUser.get()); // User(name=卡诺1, age=11, gender=0) 6 findAny 获取任意一个 使用方式类比findFirst，获取任意一个(串行流中一般返回的是第一个，并行流中是随机的) // 串行流 Optional findAny = Stream.of(1, 2, 3, 4).findAny(); System.out.println(findAny.get()); // 并行流 Optional findAny2 = Stream.of(1, 2, 3, 4).parallel().findAny(); System.out.println(findAny2.get()); 注意： parallel()可以将串行流转化成并行流 allMatch、anyMatch、noneMacth 接收一个Predicate类型的表达式 7 allMacth 全部匹配 // 判断元素是否都大于3 Predicate predicate = (i) -> i > 3; boolean allGt3 = Stream.of(1, 2, 3, 4).allMatch(predicate); System.out.println(allGt3); // false allGt3 = Stream.of(4, 5, 6).allMatch(predicate); System.out.println(allGt3); // true 8 anyMatch 至少匹配一个 // 判断是否存在大于3的元素 Predicate predicate = (i) -> i > 3; boolean anyGt3 = Stream.of(1, 2).anyMatch(predicate); System.out.println(anyGt3); // false anyGt3 = Stream.of(4, 5, 6).anyMatch(predicate); System.out.println(anyGt3); // true 9 noneMacth 没有匹配到任何一个 // 判断是否存在大于3的元素 Predicate predicate = (i) -> i > 3; boolean anyGt3 = Stream.of(1, 2).noneMatch(predicate); System.out.println(anyGt3); // true anyGt3 = Stream.of(4, 5, 6).noneMatch(predicate); System.out.println(anyGt3); // false 10 reduce 归约 将元素序列通过指定的算法反复结合，最终得到一个结果，一般用来计算sum等，reduce是个重载方法，包含 单参: reduce(BinaryOperator accumulator) 双参数: reduce(T identity, BinaryOperator accumulator), 第一个入参可以认为是一个初始化数据 三参数: reduce(U identity, BiFunction accumulator, BinaryOperator combiner), 第三个参数在串行流中不触发，效果等同与双参，但在并行流它用于合并计算 // 求和 【单参】 Optional reduceOptional = Stream.of(1, 2).reduce(Integer::sum); System.out.println(reduceOptional.get()); // 3 // 求和，增加一个初始化值参与计算 【双参】 Integer reduce = Stream.of(1, 2).reduce(1, Integer::sum); System.out.println(reduce); // 4 // 并行流三参 Integer sum = Stream.of(1, 2, 3).parallel().reduce(4, (t1, t2) -> { String log = String.join(\" | \",\"中间参数\", Thread.currentThread().getName(), t1 + \" + \" + t2); System.out.println(log); return t1 + t2; }, (t1, t2) -> { String log = String.join(\" | \", \"第三个参数\", Thread.currentThread().getName(), t1 + \" + \" + t2); System.out.println(log); return t1 + t2 ; }); System.out.println(sum); //5 // 串行流三参 sum = Stream.of(1, 2, 3).reduce(4, (t1, t2) -> { String log = String.join(\" | \",\"中间参数\", Thread.currentThread().getName(), t1 + \" + \" + t2); System.out.println(log); return t1 + t2; }, (t1, t2) -> { System.out.println(\"执行了第三个参数\"); return t1 + t2 ; }); System.out.println(sum); // 3 输出结果为： 中间参数 | main | 4 + 2 中间参数 | ForkJoinPool.commonPool-worker-9 | 4 + 1 中间参数 | ForkJoinPool.commonPool-worker-2 | 4 + 3 第三个参数 | ForkJoinPool.commonPool-worker-2 | 6 + 7 第三个参数 | ForkJoinPool.commonPool-worker-2 | 5 + 1318 中间参数 | main | 4 + 1 中间参数 | main | 5 + 2 中间参数 | main | 7 + 310 通过上述输出结果可以看出，并行流中第二个参数使用初始值分别和流中每个元素相加，得出的结果再交给第三个参数进行合并，看起来怪怪的。 11 collect 收集 将结果收集为多种类型：常用的有 collect(Collectors.toList()) collect(Collectors.toSet()) collect(Collectors.toMap()) collect(Collectors.groupingBy())， 更多的查看java.util.stream.Collectors下提供的方法！ // collect(Collectors.toList()) 收集为list List nameList = userStream().map(User::getName).collect(Collectors.toList()); System.out.println(nameList); // [卡诺1, 卡诺2, 卡诺3, 卡诺4, 卡诺5] // collect(Collectors.toSet()) 搜集为set Set set = Arrays.asList(1, 2, 3, 1).stream().collect(Collectors.toSet()); System.out.println(set); // [1, 2, 3] // collect(Collectors.toMap()) 根据名称收集为map，如果key重复需要使用toMap的三参数，设置为覆盖 Map firstUserMap = userStream().limit(1).collect(Collectors.toMap(User::getName, Function.identity())); System.out.println(firstUserMap); // {卡诺1=User(name=卡诺1, age=11, gender=0)} // collect(Collectors.groupingBy()) 根据名称分组 Map> collect = userStream().limit(1).collect(Collectors.groupingBy(User::getName)); System.out.println(collect); // {卡诺1=[User(name=卡诺1, age=11, gender=0)]} 以上仅列出常见的Stream操作，Lambda中有特化的内置函数接口，Stream也有，比如：IntStream、LongStream等，使用流程和Stream一样，或增加一些常用的统计方法比如sum等。 12 parallelstream并行流 上面我们探讨的大都是串行流，而Java同样也为我们提供了更加快捷的并行处理方式，并行流就是将一块内容分成多块交由不同的线程处理，线程池由ForkJoinPool.commonPool()提供，底层使用Fork/Join框架实现，而串行流转化成并行流的方式也很简单，如下： Stream.of().parallel() 并行流的代码整体操作与串行流几乎无异，但是由于它使用的公共ForkJoinPool。所以尽可能避免操作阻塞、重量级的任务，否则会导致其他依赖并行流的部分变得缓慢。 3.4 总结 本章主要针对Stream进行讲解，并结合Lambda给出相关案例； Stream使用包括：创建流->中间操作->终端操作，其中中间操作可以包含多个； parallelstream并行流需要考虑线程安全的相关问题（死锁、事物等）所以它更适合没有线程安全问题的数据处理，stream则适合线程安全、阻塞、重量级任务的处理； 4 Files.lines使用注意事项 Files.lines()方法使用相关问题 4.1 使用try-with-resources 从path对应的文件中读取所有内容,并按行分割,返回一个Stream. 因为是流，使用完后必须得关闭流，否则会报/proc/stat: Too many open files 使用try-with-resources语句来保证stream的close方法被调用,从而关闭打开的文件: try(Stream stream = Files.lines(Paths.get(file))){ return stream.skip(start).limit(limit).collect(Collectors.toList()); } catch (IOException e){ logger.error(\"get content from{} error,{}\",file, e.getMessage()); } //等价于： Stream stream = Files.lines(Paths.get(file)); try { return stream.skip(start).limit(limit).collect(Collectors.toList()); } catch (IOException e){ logger.error(\"get content from{} error,{}\",file, e.getMessage()); } finally { stream.close(); } 5 spring xml bean的property的简写——p命令空间 对“setter方法注入”进行简化，替换，不再用， 而是在bean标签里 p命名空间使用前提，必须添加命名空间: Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-05-05 17:34:07 "},"4week/5_6/":{"url":"4week/5_6/","title":"Spring Batch -- FlatFileItemReader","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 Spring Batch -- FlatFileItemReader 1.1 property/该类的字段 1.2 字段所对应的类/接口 1.3 各接口定义 1.3.1 RecordSeparatorPolicy 1.3.2 LineMapper 1.4 LineMapper之DefaultLineMapper详解 1.4.1 LineTokenizer 1.4.2 FieldSetMapper 1.5 LineCallbackHandler 1.5.1 自定义实现LineCallbackHandler 第4周-5.6 1 Spring Batch -- FlatFileItemReader Spring Batch之读数据—FlatFileItemReader（二十五） 实现ItemReader接口，核心作用将Flat文件中的记录转换为Java对象。 Flat File: 是一种包含没有相对关系结构的记录的文件。说白了就是不像表那样有结构，而是文本文档一样记录的数据。 1.1 property/该类的字段 属性 类型 说明 bufferedReaderFactory BufferedReaderFactory 根据给定的resource创建BufferReader实例，默认使用DefaultBufferedReaderFactory创建文本类型的BufferReader实例。 comments String[] 定义注释行的前缀，当某行以这些字符串中的一个开头时候，此行记录将会被Spring Batch框架忽略。 encoding String 读取文件的编码类型，默认值为从环境变量file.encoding获取，如果没有设置则默认为UTF-8 lineMapper LineMapper 将一行文件记录转换为Java对象 linesToSkip int 读取文件的时候，定义跳过文件的行数；跳过的行记录将会被传递给skippedLinesCallback，执行跳过行的回调操作 recordSeparatorPolicy RecordSeparatorPolicy 定义文件如何区分记录，可以按照单行、也可以按照多行区分记录 resource Resource 需要读取的资源文件 skippedLinesCallback LineCallbackHandler 定义文件中记录跳过时执行的回调操作，通常与linesToSkip一起使用 strict boolean 定义读取文件不存在时候的策略，如果为true则抛出异常；如果为false表示不抛出异常，默认值为true 1.2 字段所对应的类/接口 红色部分： 关键类 说明 Resource 定义读取的文件资源 RecordSeparatorPolicy 从文件中确定一条记录的策略，记录可能是一行，可能是跨多行 LineMapper 将一条记录转化为Java数据对象，通常由LineTokenizer和FieldSetMapper组合来实现该功能 LineTokenizer 将一条记录分割为多个字段，在LineMapper的默认实现DefaultLineMapper中使用 FieldSetMapper 将多个字段值转化为Java对象，在LIneMapper的默认实现DefaultLineMapper中使用 LineCallbackHandler 处理文件中记录回调处理操作 1.3 各接口定义 1.3.1 RecordSeparatorPolicy //org.springframework.batch.item.file.separator.RecordSeparatorPolicy public interface RecordSeparatorPolicy { //操作定义记录是否结束 boolean isEndOfRecord(String var1); //操作在一个新行加入到记录前触发 String postProcess(String var1); //操作在一个完整记录返回前触发 String preProcess(String var1); } FlatFileItemReader默认使用SimpleRecordSeparatorPolicy作为记录分割策略，即每一行作为一条记录。 1.3.2 LineMapper //org.springframework.batch.item.file.mapping.LineMapper public interface LineMapper { //传入的参数是行的内容和行号，返回值为转换后的领域对象(通常为Java对象)。 T mapLine(String var1, int var2) throws Exception; } 4个默认实现： LineMapper 说明 1 DefaultLineMapper 默认的行转换类，引用接口LineToken和FieldSetMapper完成数据转换；LineTokenizer负责将一条记录转换为对象FieldSet(可以看作是一个key-value对的组合)，FieldSetMapper负责将FieldSet转换为领域对象 DefaultLineMapper 2 JsonLineMapper 负责将文件中JSON格式的文本数据转换为领域对象，转换后的领域对象格式为Map JsonLineMapper 3 PassThroughLineMapper 最简化的数据转换实现类，将一条记录直接返回，可以认为返回的领域对象为String类型的格式 PassThroughLineMapper 4 PatternMatchingCompositeLineMapper 复杂数据转换类，可以为不同的记录定义不同的LineTokenizer和FieldSetMapper来实现数据转换；在执行过程中，根据每条记录的内容根据设置的条件找到匹配的LineTokenizer和FieldSetMapper进行数据转换；多用于处理同一文件中有不同类型记录的场景。可以认为PatternMatchingCompositeLineMapper组合了多个DefaultLineMapper PatternMatchingCompositeLineMapper 1.4 LineMapper之DefaultLineMapper详解 DefaultLineMapper是Spring Batch框架提供的一种LIneMapper实现，其默认使用 LineTokenizer: 负责将一条记录转换为FieldSet对象 FieldSetMapper: 负责将FieldSet对象转换为领域对象 完成数据转换功能。 DefaultLineMapper通过组合的方式将任务委托给两个接口来完成，简化了DefaultLineMapper的代码结构，同时使得每个对象完成的任务职责非常简单，保持了代码结构清晰。 配置DefaultLineMapper的实例代码： 1.4.1 LineTokenizer public interface LineTokenizer { //传入的参数是行的内容，返回值为FieldSet对象。 //FieldSet对象中可以认为是一组key-value的组合， //负责存放每条记录分割后的数据条目， //条目以key-value(key可以认为是字段的名字name)的方式存在。 FieldSet tokenize(String var1); } FieldSet接口中定义了读取value值的基本类型操作，以及操作name相关的方法。在FieldSet中读取value时，支持直接转换为类型String、Boolean、Char、Byte、Short、Int、Long、Float、Double、BigDecimal、Date。 4类默认的实现： LineTokenizer 说明 DelimitedLineTokenizer 基于分隔符的行转换，根据给定的分隔符将一条记录转换为FieldSet对象org.springframework.batch.item.file.transform.DelimitedLineTokenizer FixedLengthTokenizer 基于定长数据的行转换，根据给定的数据长度将一条记录转换为FieldSet对象org.springframework.batch.item.file.transform.FixedLengthTokenizer RegexLineTokenizer 根据正则表达式的条件将一条记录转换为FieldSet对象org.springframework.batch.item.file.transform.RegexLineTokenizer PatternMatchingCompositeLineTokenizer 可以为不同的记录定义不同的LineTokenizer；在执行过程中根据给定的标识与每条记录比对，如果满足则用指定的LineTokenizer；多用于处理同一文件中有不同类型记录的场场景org.springframework.batch.item.file.transform.PatternMatchingCompositeLineTokenizer 1. DelimitedLineTokenizer: 分隔符文件配置 例： ① 待处理的以“,”为分隔符的文件: 4047390012345678,tom,100.00,2013-2-2 12:00:08,Lu Jia Zui road 4047390012345678,tom,320.00,2013-2-3 10:35:21,Lu Jia Zui road 4047390012345678,tom,674.70,2013-2-6 16:26:49,South Linyi road 4047390012345678,tom,793.20,2013-2-9 15:15:37,Longyang road 4047390012345678,tom,360.00,2013-2-11 11:12:38,Longyang road 4047390012345678,tom,893.00,2013-2-28 20:34:19,Hunan road ② 配置分隔符DelimitedLineTokenizer： accountID name amount date address delimiter：表示分隔符为“,”。 names：为每个字段定义名字，根据分隔符“,”获取的每个字段值分别对应names中定义的名字。 2. FixedLengthTokenizer: 定长类型文件处理 例： ① 如下是定长文件，每行记录长度一致，字段间不足的使用空格补齐，每个字段的固定长度为1-16，17-26,27-34,35-53,54-72： 4041390012345678tom 00100.002013-02-02 12:00:08 Lu Jia Zui road 4042390012345678tom 00320.002013-02-03 10:35:21 Lu Jia Zui road 4043390012345678jerry 00674.702013-02-06 16:26:49 South Linyi road 4044390012345678rose 00793.202013-02-09 15:15:37 Longyang road 4045390012345678bruce 00360.002013-02-11 11:12:38 Longyang road 4046390012345678rachle 00893.002013-02-28 20:34:19 Hunan road ② 配置定长文件FixedLengthTokenizer： columns：定义字段长度，字段顺序和names定义的名字匹配。 names：属性names为每个字段定义名字。 说明：定义字段长度时，从1开始，而不是从0开始。 1.4.2 FieldSetMapper public interface FieldSetMapper { //传入的参数是FieldSet对象，返回值为转换后的领域对象。 T mapFieldSet(FieldSet var1) throws BindException; } 3类默认的实现： FieldSetMapper 说明 ArrayFieldSetMapper 将FieldSet对象转换为为String[] org.springframework.batch.item.file.mapping.ArrayFieldSetMapper BeanWrapperFieldSetMapper 将FieldSet对象根据名字映射到给定的Bean中，需要保证FieldSet中的name和Bean中属性的名称一致. org.springframework.batch.item.file.mapping.BeanWrapperFieldSetMapper PassThroughFieldSetMapper 直接返回FieldSet对象. org.springframework.batch.item.file.mapping.PassThroughFieldSetMapper 1 BeanWrapperFieldSetMapper BeanWrapperFieldSetMapper提供了一种方便的方式，将FieldSet对象根据名字直接映射成领域对象。如果声明使用BeanWrapperFieldSetMapper，只需要在属性prototypeBeanName中指明需要映射的领域对象即可，在运行期自动将FieldSet中name与领域对象同名的属性进行赋值操作。 配置信息： 其中CreditBill.java： public class CreditBill implements Serializable{ private static final long serialVersionUID = -4940717436114184875L; private String accountID = \"\"; /** 银行卡账户ID */ private String name = \"\"; /** 持卡人姓名 */ private double amount = 0; /** 消费金额 */ private String date; /** 消费日期 ，格式YYYY-MM-DD HH:MM:SS*/ private String address; /** 消费场所 **/ } 2 自定义FieldSetMapper 直接实现接口FieldSetMapper，可以实现自定义的转换器， public class CreditBillFieldSetMapper implements FieldSetMapper { public CreditBill mapFieldSet(FieldSet fieldSet) throws BindException { CreditBill result = new CreditBill(); result.setId(fieldSet.readString(\"id\")); result.setAccountID(fieldSet.readString(\"accountID\")); result.setName(fieldSet.readString(\"name\")); result.setAmount(fieldSet.readDouble(\"amount\")); result.setDate(fieldSet.readString(\"date\")); result.setAddress(fieldSet.readString(\"address\")); return result; } } //配置 1.5 LineCallbackHandler 在FlatFileItemReader中定义属性linesToSkip，表示从文件头开始跳过指定的行；当记录被跳过时，会触发接口LineCallbackHander中的handleLine()操作，该操作中能够获取跳过的行内容。 经常使用的场景是将Falt文件中的文件头跳过后，然后将跳过的文件头内容直接写到目标文件的文件头中，这可以通过实现LineCallbcckHandler接口来完成。 LineCallbackHandler接口定义如下： public interface LineCallbackHandler { //每次跳过时均会被触发 void handleLine(String var1); } 1.5.1 自定义实现LineCallbackHandler 实现接口LineCallbackHandler，将跳过的文件内容写入到目标文件中： public class CopyHeaderLineCallbackHandler implements LineCallbackHandler, FlatFileHeaderCallback { private String header = \"\"; //负责收集读文件跳过的头记录 public void handleLine(String line) { this.header = line; } //负责写入到目标文件中 public void writeHeader(Writer writer) throws IOException { writer.write(header); } } 其中，接口FlatFileHeaderCallback用于定义在ItemWrite之前写入特定的文件头，主要的操作是writeHeader(). 配置信息： ......... ......... Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-05-06 11:18:16 "},"4week/5_7/":{"url":"4week/5_7/","title":"DataOutputStream和DataInputStream","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 HttpURLConnection 2 DataOutputStream和DataInputStream 2.1 DataOutputStream 2.2 DataInputStream 2.3 写入文件打开显示乱码 第4周-5.7 1 HttpURLConnection HttpURLConnection 2 DataOutputStream和DataInputStream Java语言DataOutputStream和DataInputStream使用方法 2.1 DataOutputStream //创建数据写入流(写入到文件),第二个参数为true意思是追加写入，而不是覆盖写入 DataOutputStream dos = new DataOutputStream(new FileOutputStream(\"water.txt\",true));. //写入数据 dos.writeInt(int类型的数据); //写入int类型 dos.writeDouble(double类型的数据); //写入double类型 ... 2.2 DataInputStream 注意：这里的读取顺序要和写入顺序一样，且次数也要一样 //创建数据读取流(从文件读取) DataInputStream dis = new DataInputStream(new FileInputStream(\"water.txt\")); //读取数据 dis.readInt() //获取int类型 dis.readDouble() //获取double类型 2.3 写入文件打开显示乱码 乱码原因： 和ObjectOutputStream.writeObject()乱码的原因差不多，DataOutputStream写入文件，直接打开就是乱码的，只有用DataInputStream读取才能还原，而且读取的顺序和次数必须和写入的顺序次数一样。 ObjectOutputStream.writeObject()的作用是把一个实例的对象以文件的形式保存到磁盘上， 这个过程就叫Java对象的持久化。而这个文件是以二进制的形式编写的，当你用文本编辑器将它打开，这些二进制代码与某个字符集映射之后，显示出来的东西就成了乱码。（即使输出的是一个String的对象，也是以该String对象的二进制编码的形式输出，而不是输出String对象的内容。）我们需要通过ObjectInputStream来进行读取。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-05-09 15:15:14 "},"5week/5_9/":{"url":"5week/5_9/","title":"TLS-v1.2与SSL-v3.1","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 IDEA 比较两个文件差异 2 TLS-v1.2与SSL-v3.1 2.1 TLSv1.2协议 2.1.1 TLS传输过程 2.1.2 传输过程总体描述 2.1.3 传输中的一些参数 2.1.4 身份验证过程 2.2 SSL 3 cp -p 4 File.renameTo 5 git合并多次提交为1次 5.1 输入git rebase -i 5.2 弹出目的编辑窗口 5.3 push到远程 5.4 pull到本地 第5周-5.9 1 IDEA 比较两个文件差异 在目录树里选中两个文件，右键->compare files。 2 TLS-v1.2与SSL-v3.1 TLSv1.2介绍及Https协议SSL建立过程分析（OpenSSL源码） SSL3.1就是TLS1.0 2.1 TLSv1.2协议 3个作用： 身份认证：通过证书认证来确认对方的身份，防止中间人攻击 数据私密性：使用对称性密钥加密传输的数据，由于密钥只有客户端/服务端有，其他人无法窥探。 数据完整性：使用摘要算法对报文进行计算，收到消息后校验该值防止数据被篡改或丢失。 2.1.1 TLS传输过程 使用wireshark抓包的结果： 其中1-4是握手阶段，5是指握手后双方使用商议好的秘钥进行通讯。 2中并列着Server Hello,Certificate等多个类型，是因为这是一个Multiple Handshake Messages，一次性发送多个握手协议包，如下图所示： 2.1.2 传输过程总体描述 （1）客户端提供【客户端随机数、可选算法套件、sessionId】等信息 （2）服务端提供【服务端随机数、选用算法套件、sessionId】等信息 （3）服务端提供证书 （4）服务端与客户端互换算法需要的参数 （5）客户端根据前面提到的随机数和参数生成master secret，确认开始使用指定算法加密，并将握手信息加密传输给服务端，用来校验握手信息、秘钥是否正确 （6）服务端进行与（5）一样的操作 （7）客户端、服务端可以用master secret进行加密通讯 2.1.3 传输中的一些参数 cipher suites：算法套件 每个算法套件是一组算法，以TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256为例。 其中 ECDHE：用于协商秘钥 https://blog.csdn.net/mrpre/article/details/78025940 RSA：用于身份验证 AES_128_GCM：用于对称加密通讯 SHA256：用于生成摘要，验证数据完整性 秘钥协商过程 这里涉及到几个参数，client random，server random，pre master key，master key，其中master key是最终协商出来的秘钥，后续对称加密通讯都是使用master key。 （1）master key是使用伪随机算法，结合client random，server random，pre master key三个随机因素生成的。 （2）client random和server random是客户端和服务端分别生成的随机数，这样增加了随机性。 （3）pre master key也是通过一定规则计算出来的随机数。 我们依旧以TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256为例讲述一下pre master key的生成过程。 ① 客户端随机生成随机值Ra，计算Pa = Ra Q(x, y)，Q(x, y)为全世界公认的某个椭圆曲线算法的基点。将Pa发送至服务器。 ② 服务器随机生成随机值Rb，计算Pb - Rb Q(x, y)。将Pb发送至客户端。 由于算法的不可逆转性，外界无法通过Pa、Pb推算出Ra、Rb ③ 因为算法保证了Ra Pb= Rb Pa，所以客户端计算S = Ra Pb；服务器计算S = Rb Pa，提取其中的S的x向量作为密钥（pre master key） TLS握手过程中服务器和客户端互换参数，就是在交换Pa和Pb，交换后服务器和客户端可根据ECDHE算出同一个pre master key。 2.1.4 身份验证过程 做两件事情： 确认服务器发送过来的证书是合法的 确认服务器拥有私钥 1 验证证书合法性 以csdn网站为例，其证书结构如下： 服务端发送证书给客户端时，需要发送整个证书链（这里没有传输根证书，我认为是因为浏览器自带了根证书，并且信任它） 每个证书包含了一些基本信息、证书公钥和证书签名。其中证书签名是对证书进行摘要计算，并使用颁发机构的私钥加密生成。 为证实csdn.net证书的合法性，我们需要用GeoTrust RSA CA 2018的公钥对证书签名进行解密，解密后与证书的摘要进行对比，一致证明csdn.net证书是没有问题的。 同样的，我们需要证明GeoTrust RSA CA 2018的合法性，使用DigiCert的公钥。 DigiCert是浏览器信任的根证书，无需校验。 2 验证服务器拥有私钥 如果密钥协商过程使用的是RSA算法，则已经验证了服务器拥有私钥 如果密钥协商过程使用的是ECDHE算法，则没有验证服务器的私钥，此时需要在server key exchange时，对数据进行摘要计算并使用私钥加密，如果客户端可以使用公钥正常解密，则证明服务器拥有私钥。 3 sessionId - 握手重用 在Hello的过程中，有一个sessionId的字段，是用来重用握手信息的。 （1）第一次握手的时候 客户端发送的sessionId为空，服务端会生成sessionId返回给客户端，并将握手信息保存起来。 （2）再次握手的时候 客户端发送【上次的sessionId】，服务端检查到sessionId存在，返回同样的sessionId，然后就可以直接使用上次商定的秘钥进行通讯了。 （3）session过期时 客户端发送【上次的sessionId】，服务端检查到sessionId不存在，则返回新的sessionId，继续正常的握手流程。 2.2 SSL SSL协议,当前版本为3.1(SSL3.1就是TLS1.0)。它已被广泛地用于Web浏览器与服务器之间的身份认证和加密数据传输.它位于TCP/IP协议与各种应用层协议之间，为数据通讯提供安全支持。 详情可查看： 以前的笔记 TLSv1.2介绍及Https协议SSL建立过程分析（OpenSSL源码） 3 cp -p 命令cp -a 和 cp -p 有什么区别？ 参数 意思 -a 相当于 -pdr 的意思（参数pdr分别为：保留权限，复制软链接本身，递归复制）； -p 连同档案的属性一起复制过去，而非使用预设属性； -d 若来源文件为连结文件的属性(link file)，则复制连结文件属性而非档案本身； -f 为强制 (force) 的意思，若有重复或其它疑问时，不会询问使用者，而强制复制； -i 若目的档(destination)已经存在时，在覆盖时会先询问是否真的动作！ -l 进行硬式连结 (hard link) 的连结档建立，而非复制档案本身； -r 递归持续复制，用于目录的复制行为； -s 复制成为符号连结文件 (symbolic link)，亦即『快捷方式』档案； -u 若 destination 比 source 旧才更新 destination。 4 File.renameTo JAVA——File.renameTo方法，需要注意的坑 如果被重命名的文件已存在，那么renameTo()不会成功 renameTo()成功后，原文件会被删除 5 git合并多次提交为1次 git实用技巧：将多次commit合并为一次 5.1 输入git rebase -i git rebase -i a77517ad7fda85ba98f207: 合并(a77517ad7fda85ba98f207, head所指向的历史提交]为1次提交 5.2 弹出目的编辑窗口 除第一行外的pick改成s后wq保存退出，会弹出最后的成功提示，再次wq保存退出即可。 可以看注释，有详细解释 5.3 push到远程 因为此时远程分支有多次提交，而本地已经合并为一次提交，所以直接push会失败，改用force参数强制用本地分支覆盖远程分支。 git push --force-with-lease 使用该命令在强制覆盖前会进行一次检查如果其他人在该分支上有提交会有一个警告，此时可以避免覆盖代码的风险。 5.4 pull到本地 拉取远程主机上被他人rebase操作然后强制推送的分支，直接使用： git pull --rebase Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-05-16 10:17:38 "},"5week/5_10/":{"url":"5week/5_10/","title":"cherry-pick与CsvToBeanBuilder","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 git cherry-pick 2 CsvToBeanBuilder 2.1 maven依赖 2.2 创建文件：user.txt 2.3 UserBean 2.4 使用CsvToBeanBuilder 2.5 运行结果 2.6 常用api 第5周-5.10 1 git cherry-pick 将其它分支上的某个commit历史提交复制到当前分支上来。 即并不是要把其它分支上的所有提交全部合并到当前分支。 例：将dev分支上commit_id为f99f2b57b7ee72d55a08e699fbeec34cbac96cb8的提交合并到master分支： 切换到master分支：git checkout master 执行cherry-pick命令：git cherry-pick f99f2b57b7ee72d55a08e699fbeec34cbac96cb8 推送到远程master仓库：git push 注意master上新的commit id与dev上的id并不相同，即只是将dev上的修改拷贝过来作为一个新的提交。 2 CsvToBeanBuilder 更优雅的解析文档中的字段-CsvToBeanBuilder 优雅地将结构化文件转成java类。 2.1 maven依赖 org.projectlombok lombok 1.18.4 com.opencsv opencsv 4.2 2.2 创建文件：user.txt 内容如下（一般线上的文件，都是严格按照规范的） tiger|M|25|shanghai hanzi|W|23|beijing xiaoming|M|18| xiaohua||12| 可见xiaohua的性别和地址不详，字段值都会为空值，方便后期文件解析以及处理。 2.3 UserBean 构造和文件对应的java类，一行即一个对象，每一列对应类的一个字段。 import com.opencsv.bean.CsvBindByPosition; import lombok.AllArgsConstructor; import lombok.Builder; import lombok.Data; import lombok.NoArgsConstructor; @Data @Builder @AllArgsConstructor @NoArgsConstructor public class User { //position为文件列的索引，从0开始，0表示第1列 @CsvBindByPosition(position = 0) private String name; @CsvBindByPosition(position = 1) private String gender; @CsvBindByPosition(position = 2) private int age; @CsvBindByPosition(position = 3) private String address; } 2.4 使用CsvToBeanBuilder import java.io.FileNotFoundException; import java.io.FileReader; import java.util.List; public class ParseFileToBeanUtils { /** * 解析文件并返回beanList * @param filePath 文件路径 * @param beanClass 对应的beanClass * @param separator 文件中使用的分割符 * @return 返回beanList * */ public static List parseFileToUserBean(String filePath,Class beanClass,char separator) throws FileNotFoundException { List users = new CsvToBeanBuilder(new FileReader(filePath)) .withType(beanClass) //构造成哪个java bean .withSeparator(separator) //结构化文件中数据之间的分隔符 .build() //开始构造 .parse(); //转换解析成列表 return users; } public static void main(String[] args) throws Exception{ String filePath = \"F:/user.txt\"; List users = parseFileToUserBean(filePath,User.class,'|'); users.forEach(user ->{ System.out.println(user.toString()); }); } } 2.5 运行结果 User(name=tiger, gender=M, age=25, address=shanghai) User(name=hanzi, gender=W, age=23, address=beijing) User(name=xiaoming, gender=M, age=18, address=) User(name=xiaohua, gender=, age=12, address=) 2.6 常用api 方法 解释 CsvToBeanBuilder withFilter(CsvToBeanFilter filter) 构造filter，过滤掉不想要的行记录。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-05-10 18:11:44 "},"5week/5_11/":{"url":"5week/5_11/","title":"availableProcessors","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 Runtime.availableProcessors() 1.1 功能 1.2 返回可用核心数 1.3 jdk源码实现 1.3.1 windows 1.3.2 linux 1.4 性能比较 1.4.1 测试代码 1.4.2 cpu满负荷代码 1.4.3 开始测试 1.4.4 测试结果 1.5 总结 第5周-5.11 1 Runtime.availableProcessors() Runtime.availableProcessors() 分析 1.1 功能 返回jvm虚拟机可用核心数：返回机器可用的CPU数， 这个值有可能在虚拟机的特定调用期间更改。 1.2 返回可用核心数 在一个多核CPU服务器上，可能安装了多个应用，JVM只是其中的一个部分，有些cpu被其他应用使用了。 因此只能返回未被使用的cpu个数。 1.3 jdk源码实现 1.3.1 windows 不仅需要判断CPU是否可用，还需要依据CPU亲和性去判断是否该线程可用该CPU。里面通过一个while循环去解析CPU亲和性掩码，因此这是一个CPU密集型的操作。 1.3.2 linux linux 实现比较懒，直接通过sysconf函数读取系统参数_SC_NPROCESSORS_ONLN。 1.4 性能比较 分正常工作和cpu满负荷工作进行比较。 1.4.1 测试代码 public class RuntimeDemo { private static final int EXEC_TIMES = 100_0000; private static final int TEST_TIME = 10; public static void main(String[] args) throws Exception{ int[] arr = new int[TEST_TIME]; for(int i = 0; i 1.4.2 cpu满负荷代码 public class CpuIntesive { private static final int THREAD_COUNT = 16; public static void main(String[] args) { for(int i = 0; i { long count = 1000_0000_0000L; long index=0; long sum = 0; while(index 1.4.3 开始测试 正常工作：直接跑测试代码； 满负荷工作：先把cpu满负荷代码跑起来，再跑测试代码。 1.4.4 测试结果 系统 配置 测试方法 测试结果 Windows 2核8G 正常 1425.2ms Windows 2核8G 满负荷 6113.1ms MacOS 4核8G 正常 69.4ms MacOS 4核8G 满负荷 322.8ms 1.5 总结 可见该函数性能不错，实际使用时，可不考虑该函数性能损失。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-05-11 20:46:39 "},"5week/5_13/":{"url":"5week/5_13/","title":"子类与父类的bean管理","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 spring通过配置与注解给字段赋值 2.1 @Value使用 1 普通属性 2 静态属性 2.2 @ConfigurationProperties 2 子类与父类的bean管理 2.1 单子类测试 1 测试代码 2 测试结果 3 结果总结 2.2 多子类测试 1 测试代码 2 测试结果 3 结果总结 2.3 总结两次测试 第5周-5.13 1 spring通过配置与注解给字段赋值 2.1 @Value使用 需要无参构造方法。 1 普通属性 @Value(\"${flag}\") public int flag; 不用写setter方法。 2 静态属性 public static int flag; 想给上面的静态属性使用@Value赋值，必须得将@Value写在它的setter方法上： @Value(\"${flag}\") public void setFlag(int flag){ this.flag = flag } 2.2 @ConfigurationProperties 需要无参构造方法和setter缺一不可。 2 子类与父类的bean管理 测试环境： spring-boot-starter-parent 2.6.7 java 8 如果只在子类上注解了bean，或者说只在xml配置文件中配置了子类。 父类被初始化的同时，只会把子类的实例放入spring容器管理。 2.1 单子类测试 这里测试抽象父类，普通父类和其测试结果一样。 1 测试代码 依赖 org.springframework.boot spring-boot-starter-parent 2.6.7 application.yml sonName: son fatherName: father AbstractFather类 public abstract class AbstractFather { private String fatherName = \"normalFather\"; @Value(\"${fatherName}\") private String fatherYmlName; public String getFatherYmlName() { return fatherYmlName; } public abstract String print(); public String getFatherName() { return fatherName; } public void setFatherName(String fatherName) { this.fatherName = fatherName; } } Son类 @Component public class Son extends AbstractFather{ @Value(\"${sonName}\") private String name; public String getName() { return name; } @Override public String print() { return \"son -> print\"; } public void init(){ setFatherName(\"son's father\"); } } son2类 @Override public String print() { return \"son2 -> print\"; } public void init(){ setFatherName(\"son2's father\"); } test类 @SpringBootTest(classes = {TestingWebApplication.class}) public class Test1 { @Autowired private Son son; @Autowired private Son2 son2; @Autowired @Qualifier(\"son\") //bean的id，默认id为类名的驼峰法 private AbstractFather father1; @Autowired @Qualifier(\"son2\") private AbstractFather father2; @Test public void test(){ System.out.println(son.getName()); System.out.println(son.getFatherName()); System.out.println(son.print()); System.out.println(father.getFatherName()); System.out.println(father.getFatherYmlName()); System.out.println(father.print()); } } 2 测试结果 son normalFather son -> print normalFather father son2 -> print 3 结果总结 可见即使父类没有被放入ioc容器，但因为子类在ioc容器中，父类的@Value依然可以正常工作。 2.2 多子类测试 为了模拟实际环境，采用多线程。 1 测试代码 testThreads @Test public void testThreads() throws InterruptedException { new Thread(()->{ try { son.init(); System.out.println(Thread.currentThread().getName()+\":\"+son.getFatherName()); Thread.sleep(100); System.out.println(Thread.currentThread().getName()+\":\"+son.getFatherName()); } catch (InterruptedException e) { e.printStackTrace(); } },\"thread-1\").start(); Thread thread2 = new Thread(()->{ try { son2.init(); System.out.println(Thread.currentThread().getName()+\":\"+son2.getFatherName()); Thread.sleep(500); System.out.println(Thread.currentThread().getName()+\":\"+son2.getFatherName()); } catch (InterruptedException e) { e.printStackTrace(); } },\"thread-2\"); thread2.start(); thread2.join(); System.out.println(son); System.out.println(son2); System.out.println(father1); System.out.println(father2); } 2 测试结果 thread-1:son's father thread-2:son2's father thread-1:son's father thread-2:son2's father com.qgao.test.Son@1a5b8489 com.qgao.test.Son2@6f8f8a80 com.qgao.test.Son@1a5b8489 com.qgao.test.Son2@6f8f8a80 3 结果总结 可见在spring环境下，虽然两个不同的子类（单例模式）都继承了相同的父类，但是父类的对象并没有纳入spring的ioc容器中。 2.3 总结两次测试 当子类被放入ioc容器，父类未被放入ioc容器，但父类中有@Value， 实际上是子类将父类中的被@Value注解的字段当成自己的了。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-05-13 14:52:54 "},"6week/5_17/":{"url":"6week/5_17/","title":"spring的jdbcTemplate","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 spring的jdbcTemplate 2 java 10 新特性 var 第6周-5.17 2022-5-17 17:16:41 1 spring的jdbcTemplate Spring--JdbcTemplate简介和常用API 其中有一个方法： Object queryForObject(String sql, Object[] args, int[] argTypes, RowMapper rowMapper) 查询给定SQL以从SQL创建预准备语句以及绑定到查询的参数列表，通过RowMapper将单个结果行映射到Java对象。 例： 构造RowMapper来返回一个Admin对象： RowMapper rowmapper = new RowMapper<>() { public Admin mapRow(ResultSet rs, int index) throws SQLException { int id=rs.getInt(\"id\"); String name = rs.getString(\"name\"); String pwd = rs.getString(\"password\"); return new Admin(id, name, pwd); } }; String sql = \"select * from admin_info where id = ?\"; JdbcTemplate jdbcTemplate = getCtx().getBean(\"jdbcTemplate\", JdbcTemplate.class); Admin admin = jdbcTemplate.queryForObject(sql, new Object[]{ 100 }, rowmapper); System.out.println(admin); 原理很简单，jdbcTemplate.queryForObject会直接回调你实现的mapRow方法， 2 java 10 新特性 var Java 10 可以让编译器帮我们推断其类型： var 变量名 = 初始值; var只能在方法里定义，不允许定义类的成员变量。 var每次只能定义一个变量，不能符合声明变量。（var a,b;是不允许的） 什么时候该用var定义变量： 如果你定义变量时，给变量赋给一个直观的值，这时就可以使用var定义变量， Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-05-17 18:16:50 "},"6week/5_18/":{"url":"6week/5_18/","title":"spring的schedule定时任务","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 spring的schedule定时任务 1.1 使用方法 1.2 cron表达式 1.2.1 格式 1.2.2 占位符解释 1.2.3 案例 1.3 使定时任务多线程非阻塞运行 1.3.1 默认情况下阻塞的原因 1.3.2 解决 1.4 spring schedule原理--整个流程解析 1.4.1 从启动类上的@EnableScheduling开始 1.4.2 BeanPostProcessor接口 1.4.3 ApplicationListener接口 2 spring @Import 第6周-5.18 spring schedule定时任务详解 @Scheduled(cron = \" \") cron表达式详解 1 spring的schedule定时任务 1.1 使用方法 1 启动类使用@EnableScheduling注解开启定时任务 @SpringBootApplication @EnableScheduling public class ScheduledTest { public static void main(String[] args) { SpringApplication.run(ScheduledTest.class); } } 2 添加定时任务 2.1 使用@Scheduled注解 @Scheduled(cron = \"0/2 * * * * ? \") public void index1() { log.info(\"定时任务1，2秒执行一次，time：\" + DateTime.now() + \" 线程：\" + Thread.currentThread().getName()); } 2.2 实现SchedulingConfigurer接口 @Configuration @Component @Slf4j public class TestTask implements SchedulingConfigurer { @Override public void configureTasks(ScheduledTaskRegistrar taskRegistrar) { taskRegistrar.addFixedDelayTask(this::index2, 1000); } public void index2() { log.info(\"定时任务2，1秒执行一次，time：\" + DateTime.now() + \" 线程：\" + Thread.currentThread().getName()); } } 1.2 cron表达式 1.2.1 格式 {秒数} {分钟} {小时} {日期} {月份} {星期} {年份(可为空)} 1.2.2 占位符解释 占位符 解释 {秒数}{分钟} 允许值范围: 0~59 ,不允许为空值，若值不合法，调度器将抛出SchedulerException异常 * 代表每隔1秒钟触发； , 代表在指定的秒数触发，比如”0,15,45”代表0秒、15秒和45秒时触发任务 - 代表在指定的范围内触发，比如”25-45”代表从25秒开始触发到45秒结束触发，每隔1秒触发1次 / 代表触发步进(step)，”/”前面的值代表初始值(““等同”0”)，后面的值代表偏移量，比如”0/20”或者”/20”代表从0秒钟开始，每隔20秒钟触发1次，即0秒触发1次，20秒触发1次，40秒触发1次；”5/20”代表5秒触发1次，25秒触发1次，45秒触发1次；”10-45/20”代表在[10,45]内步进20秒命中的时间点触发，即10秒触发1次，30秒触发1次 {小时} 允许值范围: 0~23 ,不允许为空值，若值不合法，调度器将抛出SchedulerException异常,占位符和秒数一样 {日期} 允许值范围: 1~31 ,不允许为空值，若值不合法，调度器将抛出SchedulerException异常 {星期} 允许值范围: 1~7 (SUN-SAT),1代表星期天(一星期的第一天)，以此类推，7代表星期六(一星期的最后一天)，不允许为空值，若值不合法，调度器将抛出SchedulerException异常 {年份} 允许值范围: 1970~2099 ,允许为空，若值不合法，调度器将抛出SchedulerException异常 注意：除了{日期}和{星期}可以使用?来实现互斥，表达无意义的信息之外，其他占位符都要具有具体的时间含义，且依赖关系为：年->月->日期(星期)->小时->分钟->秒数 1.2.3 案例 例子 解释 30 * * * * ? 每半分钟触发任务 30 10 * * * ? 每小时的10分30秒触发任务 30 10 1 * * ? 每天1点10分30秒触发任务 30 10 1 20 * ? 每月20号1点10分30秒触发任务 30 10 1 20 10 ? * 每年10月20号1点10分30秒触发任务 30 10 1 20 10 ? 2011 2011年10月20号1点10分30秒触发任务 30 10 1 ? 10 * 2011 2011年10月每天1点10分30秒触发任务 30 10 1 ? 10 SUN 2011 2011年10月每周日1点10分30秒触发任务 15,30,45 * * * * ? 每15秒，30秒，45秒时触发任务 15-45 * * * * ? 15到45秒内，每秒都触发任务 15/5 * * * * ? 每分钟的每15秒开始触发，每隔5秒触发一次 15-30/5 * * * * ? 每分钟的15秒到30秒之间开始触发，每隔5秒触发一次 0 0/3 * * * ? 每小时的第0分0秒开始，每三分钟触发一次 0 15 10 ? * MON-FRI 星期一到星期五的10点15分0秒触发任务 0 15 10 L * ? 每个月最后一天的10点15分0秒触发任务 0 15 10 LW * ? 每个月最后一个工作日的10点15分0秒触发任务 0 15 10 ? * 5L 每个月最后一个星期四的10点15分0秒触发任务 0 15 10 ? * 5#3 每个月第三周的星期四的10点15分0秒触发任务 1.3 使定时任务多线程非阻塞运行 1.3.1 默认情况下阻塞的原因 默认情况，定时任务使用的是单例线程执行器Executors.newSingleThreadScheduledExecutor()，所以当一个定时任务阻塞是，所有定时任务都不会执行。 1.3.2 解决 实现SchedulingConfigurer接口，设置任务调度器实现类。 @Configuration @Component @Slf4j public class TestTask implements SchedulingConfigurer { @Override public void configureTasks(ScheduledTaskRegistrar taskRegistrar) { ThreadFactory nameThreadFactory = new ThreadFactoryBuilder().setNameFormat(\"scheduled-%d\").build(); taskRegistrar.setScheduler(new ScheduledThreadPoolExecutor(5, nameThreadFactory, new ThreadPoolExecutor.AbortPolicy())); //丢弃任务并抛出RejectedExecutionException异常 } } 1.4 spring schedule原理--整个流程解析 1.4.1 从启动类上的@EnableScheduling开始 //进入EnableScheduling注解 @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Import(SchedulingConfiguration.class) //引用SchedulingConfiguration.class @Documented public @interface EnableScheduling {} //进入SchedulingConfiguration类 @Configuration(proxyBeanMethods = false) @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public class SchedulingConfiguration { @Bean(name = TaskManagementConfigUtils.SCHEDULED_ANNOTATION_PROCESSOR_BEAN_NAME) @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public ScheduledAnnotationBeanPostProcessor scheduledAnnotationProcessor() { return new ScheduledAnnotationBeanPostProcessor(); //实例化ScheduledAnnotationBeanPostProcessor类 } } //进入ScheduledAnnotationBeanPostProcessor类， //它实现了很多接口，后面只看BeanPostProcessor和ApplicationListener //只看内部的构造方法，registrar会用到 public ScheduledAnnotationBeanPostProcessor() { this.registrar = new ScheduledTaskRegistrar(); } 1.4.2 BeanPostProcessor接口 调用postProcessAfterInitialization后置处理器： 扫描注解（扫描@Scheduled、@Schedules注解）， 全部转换为Scheduled后， 调用processScheduled方法 processScheduled方法内部： 先创建执行runnable 获取延迟执行时间 获取cron表达式，创建CronTask，registrar中添加任务 获取固定延迟，创建FixedDelayTask，registrar中添加任务 获取固定执行间隔，创建FixedRateTask，registrar中添加任务 把所有任务都添加到scheduledTasks 【重点】 1.4.3 ApplicationListener接口 工程启动好后调用onApplicationEvent方法： 扫描所有的SchedulingConfigurer实现类，（如上面自定义的实现类） 调用configureTasks回调函数添加定时任务。（如上面自定义的实现类中的实现方法） 调用 registrar 的 afterPropertiesSet 方法。 afterPropertiesSet方法内部在给线程池中安排任务了： @Override public void afterPropertiesSet() { scheduleTasks(); } /** * Schedule all registered tasks against the underlying * {@linkplain #setTaskScheduler(TaskScheduler) task scheduler}. */ @SuppressWarnings(\"deprecation\") protected void scheduleTasks() { if (this.taskScheduler == null) { this.localExecutor = Executors.newSingleThreadScheduledExecutor(); this.taskScheduler = new ConcurrentTaskScheduler(this.localExecutor); } if (this.triggerTasks != null) { for (TriggerTask task : this.triggerTasks) { addScheduledTask(scheduleTriggerTask(task)); //下面以这个为例子 } } if (this.cronTasks != null) { for (CronTask task : this.cronTasks) { addScheduledTask(scheduleCronTask(task)); } } if (this.fixedRateTasks != null) { for (IntervalTask task : this.fixedRateTasks) { addScheduledTask(scheduleFixedRateTask(task)); } } if (this.fixedDelayTasks != null) { for (IntervalTask task : this.fixedDelayTasks) { addScheduledTask(scheduleFixedDelayTask(task)); } } } //以scheduleTriggerTask为例，将任务放进线程池 @Nullable public ScheduledTask scheduleTriggerTask(TriggerTask task) { ScheduledTask scheduledTask = this.unresolvedTasks.remove(task); boolean newTask = false; if (scheduledTask == null) { scheduledTask = new ScheduledTask(task); newTask = true; } if (this.taskScheduler != null) { scheduledTask.future = this.taskScheduler.schedule(task.getRunnable(), task.getTrigger()); } else { addTriggerTask(task); this.unresolvedTasks.put(task, scheduledTask); } return (newTask ? scheduledTask : null); } private void addScheduledTask(@Nullable ScheduledTask task) { if (task != null) { this.scheduledTasks.add(task); } } 2 spring @Import 参数value接收一个Class数组，将你传入的类以全类名作为id加入IOC容器中。 全类名：java中指的是全限定类名，相当于包名+类名。（com.syx.servlet.HelloServlet） 非限定类名：就是平常的类名。 Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-05-18 19:26:45 "},"6week/5_19/":{"url":"6week/5_19/","title":"test测试与反射修改static final","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 test测试常用注解 1.1 @RunWith 1.2 @SpringBootTest 1.3 @ActiveProfiles(\"Test\") 2 反射中get和getDeclared的区别 3 反射常用api 3.1 Class常用api 4 反射修改static final修饰的字段 4.1 修改private修饰StringBuilder类型的字段 4.2 修改final修饰StringBuilder类型的字段 4.3 修改final修饰String类型的字段（失败） 4.4 修改final修饰String类型的字段（成功） 4.5 修改static修饰StringBuilder类型的字段 4.6 修改static final修饰StringBuilder类型的字段（失败） 4.6 修改static final修饰StringBuilder类型的字段（成功） 第6周-5.19 1 test测试常用注解 Springboot Test 详解 在spring boot常这样写test： @RunWith(SpringRunner.class) @SpringBootTest(**.class) @ActiveProfiles(\"Test\") public class Test{} 1.1 @RunWith junit包下有实现，里面的value是指在Junit run之前为test准备什么样的支持。 spring支持：@RunWith(SpringRunner.class) Mock支持：@RunWith(MockitoJUnitRunner.class) springRunner是SpringJUnit4ClassRunner的子类。 1.2 @SpringBootTest 没有value，则会从当前类往上找到spring boot主类 有value，直接将该value对应的类认为是spring boot主类 主类即被@SpringBootApplication注解，，这样才能将ioc环境引入test类，test类才能使用@Autowired等将bean注入等操作。 1.3 @ActiveProfiles(\"Test\") 说白了就是去找配置文件，诸如application-**.properties/yml的文件。 2 反射中get和getDeclared的区别 get**()：获得某个类的所有的公共（public）的(字段/方法)，包括父类中的(字段/方法)。 getDeclared**()：获得某个类的所有声明的(字段/方法)，即包括public、private和proteced，但是不包括父类的申明(字段/方法)。 3 反射常用api 3.1 Class常用api （1） Field[] getFields() 返回这个类或其超类的公共字段的Field对象数组。如果Class对象描述的是基本类型或者数组类型，将返回一个长度为0的数组。 （2） Field[] getDeclaredFields() 返回这个类的全部字段对应的Field对象数组。如果Class对象描述的是基本类型或者数组类型，将返回一个长度为0的数组。 （3）Field getField(String name) 返回指定名称的Field。如果不存在对应名称的字段，则抛出异常 NoSuchFieldException 。 （4）Field getDeclaredField(String name) 返回指定名称的Field。如果不存在对应名称的字段，则抛出异常 NoSuchFieldException 。 （5） Method[] getMethods() 返回所有的公共方法，包括从超类继承来的公共方法。 （6） Method[] getDeclaredMethods() 返回这个类或者接口的所有方法，但是不包括从超类继承的方法。 （7） Constructor[] getConstructors() 返回这个类的公共构造方法。 （8） Constructor[] getDeclaredConstructors(Class... parameterTypes) 返回这个类的全部构造方法。参数类型是一个类对象的数组，该数组标识构造函数的正式参数类型，即声明的顺序。 （9） String getPackageName 得到包含这个类型的包的包名。如果该类是一个数组类型，则返回元素类型所属的包。如果是基本数据类型，则返回 “java.lang”。 4 反射修改static final修饰的字段 Java反射-修改字段值, 反射修改static final修饰的字段 4.1 修改private修饰StringBuilder类型的字段 public class Pojo { private StringBuilder name = new StringBuilder(\"default\"); public void printName() { System.out.println(name); } } //测试 Pojo p = new Pojo(); // 查看被修改以前的值 p.printName(); // 反射获取字段, name成员变量 Field nameField = p.getClass().getDeclaredField(\"name\"); // 因为name成员变量是private, 因此须要进行访问权限设定 nameField.setAccessible(true); // 使用反射进行赋值 nameField.set(p, new StringBuilder(\"111\")); // 打印查看被修改后的值 p.printName(); 4.2 修改final修饰StringBuilder类型的字段 Pojo2 p = new Pojo2(); // 查看被修改以前的值 p.printName(); // 反射获取字段, name成员变量 Field nameField = p.getClass().getDeclaredField(\"name\"); // 因为name成员变量是private, 因此须要进行访问权限设定 nameField.setAccessible(true); // 使用反射进行赋值 nameField.set(p, new StringBuilder(\"111\")); // 打印查看被修改后的值 p.printName(); 4.3 修改final修饰String类型的字段（失败） Pojo3 p = new Pojo3(); p.printName(); //\"default\" Field nameField = p.getClass().getDeclaredField(\"name\"); nameField.setAccessible(true); nameField.set(p, \"111\"); p.printName(); //\"default\" 修改失败 由于JVM在编译时期, 就把final类型的String进行了优化, 在编译时期就会把String处理成常量, 因此 Pojo3里的printName()方法被写死了： public void printName() { System.out.println(\"default\"); } 而看似name修改失败，其实修改成功了： Pojo3 p = new Pojo3(); Field nameField = p.getClass().getDeclaredField(\"name\"); nameField.setAccessible(true); nameField.set(p, \"111\"); Object name = nameField.get(p); System.out.println(name.toString()); //\"111\" 4.4 修改final修饰String类型的字段（成功） 阻止final修饰的String在JVM编译时就被处理为常量。 可以让final String类型的name的初始值通过一次运行才能获得, 那么就不会在编译时期就被处理为常量。 public class Pojo4 { // 防止JVM编译时就把\"default4\"做为常量处理 private final String name = (null == null ? \"default4\" : \"\"); //或者 //private final String name = new StringBuilder(\"default5\").toString(); ... } //测试 Pojo4 p = new Pojo4(); p.printName(); Field nameField = p.getClass().getDeclaredField(\"name\"); nameField.setAccessible(true); nameField.set(p, \"111\"); p.printName(); // \"111\" 4.5 修改static修饰StringBuilder类型的字段 成功 4.6 修改static final修饰StringBuilder类型的字段（失败） Pojo7 p = new Pojo7(); p.printName(); Field nameField = p.getClass().getDeclaredField(\"name\"); nameField.setAccessible(true); nameField.set(p, new StringBuilder(\"111\")); p.printName(); 上述代码会抛异常，反射没法修改同时被static final修饰的变量。 4.6 修改static final修饰StringBuilder类型的字段（成功） Field nameField = p.getClass().getDeclaredField(\"name\"); nameField.setAccessible(true); //去掉final修饰符 Field modifiers = nameField.getClass().getDeclaredField(\"modifiers\"); modifiers.setAccessible(true); modifiers.setInt(nameField, nameField.getModifiers() & ~Modifier.FINAL); //再修改就正常了 nameField.set(p, new StringBuilder(\"111\")); //最后加回final修饰符 modifiers.setInt(nameField, nameField.getModifiers() & ~Modifier.FINAL); Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-05-19 19:10:09 "},"6week/5_20/":{"url":"6week/5_20/","title":"oracle处理表的字段","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 oracle处理表的字段 1.1 增加一列/多列 1.2 删除一列/多列 1.3 修改表字段类型 1.3.1 字段数据为空 1.3.2 字段有数据 第6周-5.20 1 oracle处理表的字段 Oracle 中对一个表中多个列的增加和删除的sql语句 oracle怎么修改表字段类型 1.1 增加一列/多列 alter table 表名 add(列名1 VARCHAR2(20)); 1.2 删除一列/多列 alter table 表名 drop(列名1); 1.3 修改表字段类型 1.3.1 字段数据为空 alter table tb modify (name nvarchar2(20)); 1.3.2 字段有数据 改为nvarchar2(20)可以直接执行： alter table tb modify (name nvarchar2(20)); 改为varchar2(40)执行： alter table tb modify (name varchar2(40)); 会弹出“ORA-01439:要更改数据类型,则要修改的列必须为空”， 得用这个方法： /*修改原字段名name为name_tmp*/ alter table tb rename column name to name_tmp; /*增加一个和原字段名同名的字段name*/ alter table tb add name varchar2(40); /*将原字段name_tmp数据更新到增加的字段name*/ update tb set name=trim(name_tmp); /*更新完，删除原字段name_tmp*/ alter table tb drop column name_tmp; Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-05-20 18:59:11 "},"7week/5_25/":{"url":"7week/5_25/","title":"StringSubstitutor","keywords":"","body":"TreeviewCopyright © qgao 2021-* all right reserved, powered by aleen42 1 StringSubstitutor 1.1 简单使用 1.2 默认值 1.3 自定义匹配符 1.4 自定义实体类 第7周-5.25 1 StringSubstitutor String 工具之StrSubstitutor, 字符替换 字符替换，可以使用正则表达式对匹配的字符进行替换，这种方式比较灵活。 1.1 简单使用 Map valuesMap = new HashMap(); valuesMap.put(\"animal\", \"quick brown fox\"); valuesMap.put(\"target\", \"lazy dog\"); String templateString = \"The ${animal} jumped over the ${target}.\"; StringSubstitutor sub = new StringSubstitutor(valuesMap); String resolvedString = sub.replace(templateString); System.out.println(resolvedString); //output The quick brown fox jumped over the lazy dog. 1.2 默认值 如果在Map实体中没找到对应的Key值，变量就不会被替换，而是直接以字符串展示， 但是StringSubstitutor提供取值分隔符 :-，添加到变量的后面，可以为该值提供默认值。 StrSubstitutor提供了setValueDelimiterMatcher(StrMatcher), setValueDelimiter(char) or setValueDelimiter(String)三种方法，可以自定义默认取值分隔符。 templateString = \"The ${animal} jumped over the ${target}. ${undefined.number:-1234567890}.\"; String resolvedString2 = sub.replace(templateString); System.out.println(resolvedString); //output The quick brown fox jumped over the lazy dog. 1234567890. 1.3 自定义匹配符 如果字符串中的变量形式不是 ${}，而是&()，StringSubstitutor提供了不同的构造器以及setVariablePrefix(char)，setVariableSuffix(char)等方法自定义匹配符。 String templateString = \"The &(animal) jumped over the &(target). &(undefined.number:-1234567890).\"; StrSubstitutor sub = new StrSubstitutor(valuesMap, \"&(\", \")\", '&'); String resolvedString = sub.replace(templateString); System.out.println(resolvedString); //output The quick brown fox jumped over the lazy dog. 1234567890. 1.4 自定义实体类 在系统中装载数据的实体有可能不是Map,而是其它的数据实体，例如com.fasterxml.jackson.databind.node.JsonNode。 public class StrSubstitutorTest { @Test public void test() { StrSubstitutor substitutor = new StrSubstitutor(); ObjectNode context = JsonNodeFactory.instance.objectNode(); context.put(\"animal\", \"quick brown fox\"); context.put(\"target\", \"lazy dog\"); String templateString = \"The ${animal} jumped over the ${target}. ${undefined.number:-1234567890}.\"; substitutor.setVariableResolver(new JsonPathContextLookup(context)); String resolvedString = substitutor.replace(templateString); System.out.println(resolvedString); //output: The quick brown fox jumped over the lazy dog. 1234567890. } class JsonPathContextLookup extends StrLookup { private final JsonNode context; JsonPathContextLookup(JsonNode context) { super(); this.context = context; } @Override public String lookup(String key) { return Optional.ofNullable(context.get(key)).map(JsonNode::asText).orElse(null); } } } Copyright © qgao 2021-* all right reserved，powered by Gitbook该文件修订时间： 2022-05-25 19:26:30 "}}